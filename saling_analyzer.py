# app.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from datetime import datetime
import io
import re

from supabase import create_client, Client

# requestsëŠ” requirements.txtì— ë°˜ë“œì‹œ í¬í•¨
try:
    import requests
except Exception:
    requests = None


# =========================
# í˜ì´ì§€ ì„¤ì •
# =========================
st.set_page_config(
    page_title="ì„¸ë¥´ì§€ì˜¤íƒ€í‚¤ë‹ˆ íŒë§¤ ë¶„ì„",
    page_icon="ğŸ‘”",
    layout="wide"
)

# =========================
# í…œí”Œë¦¿ ì»¬ëŸ¼ ì •ì˜ (ìµœì¢…)
# - íŒë§¤: ë‹¹ì‹œì¦Œ ê¸°ì¤€ + ê°€ê²© í¬í•¨
# - ì†Œì¬: ë‘ê»˜ ì œê±°, ë°€ë„ -> ì¡°ì§
# =========================
SALES_COLS = ["í’ˆë²ˆ", "ì»¬ëŸ¬", "ê°€ê²©", "ì œì¡°ë°©ì‹", "ì†Œì¬ëª…", "í•", "ê¸°ì¥", "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]
MATERIAL_COLS = ["ì†Œì¬ëª…", "ì†Œì¬ì—…ì²´", "í˜¼ìš©ì›ë‹¨", "í˜¼ìš©ìœ¨", "ì¤‘ëŸ‰", "ì¡°ì§", "GU", "RA", "SA"]

# =========================
# Supabase ì—°ê²°
# =========================
@st.cache_resource
def init_supabase():
    try:
        url = st.secrets["SUPABASE_URL"]
        key = st.secrets["SUPABASE_KEY"]  # Streamlitì—ëŠ” anon key
        return create_client(url, key)
    except Exception as e:
        st.error(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

supabase: Client = init_supabase()


# =========================
# ìœ í‹¸: JSON-safe ë³€í™˜ (NaN/Inf ì œê±°)
# =========================
def make_json_safe_df(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    out = df.copy()
    out = out.replace([np.nan, np.inf, -np.inf], None)
    return out

# =========================
# ìœ í‹¸: í•„ìˆ˜ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ê¸°ë³¸ê°’ ë³´ì • (NOT NULL ëŒ€ë¹„)
# =========================
def fill_required_text(df: pd.DataFrame, cols, default="UNKNOWN") -> pd.DataFrame:
    out = df.copy()
    for c in cols:
        if c not in out.columns:
            out[c] = default
        out[c] = out[c].astype(str).replace(["None", "nan"], "").fillna("")
        out[c] = out[c].apply(lambda x: x.strip() if isinstance(x, str) else x)
        out[c] = out[c].replace("", default)
    return out

# =========================
# ìœ í‹¸: ì•ˆì „í•œ JSON ì‘ë‹µ ì²˜ë¦¬
# =========================
def safe_json(resp):
    try:
        return resp.json()
    except Exception:
        return None

def show_api_error(out, fallback="AI ì˜ˆì¸¡ ì‹¤íŒ¨(ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜)"):
    if isinstance(out, dict):
        return out.get("error", fallback)
    return fallback

# =========================
# ìœ í‹¸: í˜¼ìš©ìœ¨ íŒŒì‹±/íŒŒìƒ feature (ì˜ˆì¸¡ ì •í™•ë„ìš©)
# - "COTTON / POLYESTER / ELASTANE" + "74 / 21 / 5"
# - ë˜ëŠ” "NYLON/VISCOSE" + "24/76"
# =========================
FIBER_ALIASES = {
    "COTTON": ["COTTON", "CO", "CT", "COTNA"],
    "POLYESTER": ["POLYESTER", "PES", "PE", "PL"],
    "NYLON": ["NYLON", "PA", "N", "NL"],
    "RAYON": ["RAYON", "VISCOSE", "VISC", "VI", "LYOCELL", "TENCEL", "MODAL"],
    "WOOL": ["WOOL", "WL"],
    "ACRYLIC": ["ACRYLIC", "AC"],
    "SPANDEX": ["SPANDEX", "ELASTANE", "ELASTIN", "PU", "SP", "LYCRA"],
    "POLYURETHANE": ["POLYURETHANE", "PU"],
}

SYNTHETIC_SET = {"POLYESTER", "NYLON", "ACRYLIC", "POLYURETHANE"}
NATURAL_SET = {"COTTON", "WOOL"}
REGENERATED_SET = {"RAYON"}

def _norm_fiber_name(name: str) -> str:
    if not name:
        return ""
    s = str(name).strip().upper()
    s = re.sub(r"[\(\)\[\]\{\}]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    # alias mapping
    for canon, alist in FIBER_ALIASES.items():
        for a in alist:
            if s == a:
                return canon
    # ë¶€ë¶„ ì¼ì¹˜ë„ ì²˜ë¦¬
    for canon, alist in FIBER_ALIASES.items():
        for a in alist:
            if a in s:
                return canon
    return s

def parse_blend_components(blend_fibers: str, blend_ratio: str):
    """
    return: list of (fiber_canon, ratio_float)
    """
    if not blend_fibers or not blend_ratio:
        return []

    fibers = [x.strip() for x in re.split(r"[/,|]+", str(blend_fibers)) if x.strip()]
    ratios = [x.strip() for x in re.split(r"[/,|]+", str(blend_ratio)) if x.strip()]

    # ìˆ«ìë§Œ ì¶”ì¶œ
    ratios_num = []
    for r in ratios:
        m = re.findall(r"[-+]?\d*\.?\d+", r)
        if m:
            try:
                ratios_num.append(float(m[0]))
            except Exception:
                pass

    if not fibers or not ratios_num:
        return []

    # ê¸¸ì´ ë§ì¶”ê¸°: ì§§ì€ ìª½ ê¸°ì¤€
    n = min(len(fibers), len(ratios_num))
    fibers = fibers[:n]
    ratios_num = ratios_num[:n]

    # í•©ì´ 0ì´ë©´ ë¬´íš¨
    s = sum(ratios_num)
    if s <= 0:
        return []

    # ë³´ì •(í•©ì´ 100ì´ ì•„ë‹ˆì–´ë„ ìƒëŒ€ë¹„ë¡œ)
    comps = []
    for f, r in zip(fibers, ratios_num):
        fn = _norm_fiber_name(f)
        comps.append((fn, float(r)))
    return comps

def derive_blend_features(í˜¼ìš©ì›ë‹¨: str, í˜¼ìš©ìœ¨: str):
    """
    ì˜ˆì¸¡ feature:
    - pct_cotton, pct_synthetic, pct_regenerated, pct_spandex
    - n_fibers
    """
    comps = parse_blend_components(í˜¼ìš©ì›ë‹¨, í˜¼ìš©ìœ¨)
    if not comps:
        return {
            "pct_cotton": None,
            "pct_synthetic": None,
            "pct_regenerated": None,
            "pct_spandex": None,
            "n_fibers": None,
        }

    total = sum(r for _, r in comps)
    if total <= 0:
        return {
            "pct_cotton": None,
            "pct_synthetic": None,
            "pct_regenerated": None,
            "pct_spandex": None,
            "n_fibers": len(comps),
        }

    pct_cotton = 0.0
    pct_synth = 0.0
    pct_regen = 0.0
    pct_spandex = 0.0

    for f, r in comps:
        p = r / total * 100.0
        if f in NATURAL_SET:
            if f == "COTTON":
                pct_cotton += p
        if f in SYNTHETIC_SET:
            pct_synth += p
        if f in REGENERATED_SET:
            pct_regen += p
        if f in {"SPANDEX", "POLYURETHANE"}:
            pct_spandex += p

    return {
        "pct_cotton": round(pct_cotton, 2),
        "pct_synthetic": round(pct_synth, 2),
        "pct_regenerated": round(pct_regen, 2),
        "pct_spandex": round(pct_spandex, 2),
        "n_fibers": len(comps),
    }

# =========================
# ìœ í‹¸: ìƒê´€/êµ¬ê°„ ë¶„ì„
# =========================
def _bin_series(s: pd.Series, method="equal_width", bins=4):
    s = pd.to_numeric(s, errors="coerce")
    s = s.replace([np.inf, -np.inf], np.nan).dropna()
    if s.empty:
        return None
    if method == "quantile":
        return pd.qcut(s, q=bins, duplicates="drop")
    return pd.cut(s, bins=bins)

def _safe_corr(a: pd.Series, b: pd.Series):
    a = pd.to_numeric(a, errors="coerce")
    b = pd.to_numeric(b, errors="coerce")
    df2 = pd.concat([a, b], axis=1).dropna()
    if len(df2) < 3:
        return np.nan
    return df2.iloc[:, 0].corr(df2.iloc[:, 1])


# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
@st.cache_data(ttl=600)
def load_sales_data():
    if supabase is None:
        return pd.DataFrame(columns=SALES_COLS)
    try:
        res = supabase.table("sales_data").select("*").execute()
        if res.data:
            df = pd.DataFrame(res.data)
            for c in SALES_COLS:
                if c not in df.columns:
                    df[c] = None
            df = df[SALES_COLS].copy()

            for col in ["ê°€ê²©", "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

            df = fill_required_text(df, ["í’ˆë²ˆ", "ì»¬ëŸ¬", "ì œì¡°ë°©ì‹", "ì†Œì¬ëª…", "í•", "ê¸°ì¥"])
            return df
        return pd.DataFrame(columns=SALES_COLS)
    except Exception as e:
        st.error(f"íŒë§¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(columns=SALES_COLS)

@st.cache_data(ttl=600)
def load_material_data():
    """
    âœ… í˜¼ìš©ìœ¨ì€ ìˆ«ì ìºìŠ¤íŒ…í•˜ì§€ ì•ŠìŒ (ì˜ˆ: '24 / 76' ë³´ì¡´)
    """
    if supabase is None:
        return pd.DataFrame(columns=MATERIAL_COLS)
    try:
        res = supabase.table("material_data").select("*").execute()
        if res.data:
            df = pd.DataFrame(res.data)
            for c in MATERIAL_COLS:
                if c not in df.columns:
                    df[c] = None
            df = df[MATERIAL_COLS].copy()

            # ìˆ«ìí˜•: ì¤‘ëŸ‰/GU/RA/SAë§Œ
            for col in ["ì¤‘ëŸ‰", "GU", "RA", "SA"]:
                df[col] = pd.to_numeric(df[col], errors="coerce")

            # í…ìŠ¤íŠ¸ ì •ë¦¬
            for tcol in ["ì†Œì¬ëª…", "ì†Œì¬ì—…ì²´", "í˜¼ìš©ì›ë‹¨", "í˜¼ìš©ìœ¨", "ì¡°ì§"]:
                if tcol in df.columns:
                    df[tcol] = (
                        df[tcol].astype(str)
                        .replace(["None", "nan"], "")
                        .fillna("")
                        .apply(lambda x: x.strip())
                    )
            return df
        return pd.DataFrame(columns=MATERIAL_COLS)
    except Exception as e:
        st.error(f"ì†Œì¬ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(columns=MATERIAL_COLS)


# =========================
# ë°ì´í„° ì €ì¥/ì‚­ì œ
# =========================
def save_sales_data(new_df: pd.DataFrame) -> bool:
    if supabase is None:
        st.error("âŒ Supabase ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    try:
        df = new_df.copy()
        for c in SALES_COLS:
            if c not in df.columns:
                df[c] = None

        df = fill_required_text(df, ["í’ˆë²ˆ", "ì»¬ëŸ¬", "ì œì¡°ë°©ì‹", "ì†Œì¬ëª…", "í•", "ê¸°ì¥"])

        for col in ["ê°€ê²©", "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

        df = make_json_safe_df(df)

        records = df[SALES_COLS].to_dict("records")
        if not records:
            st.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        supabase.table("sales_data").insert(records).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"íŒë§¤ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def replace_sales_data(df_upload: pd.DataFrame) -> bool:
    """
    âœ… ì—…ë¡œë“œ ì¤‘ë³µ í­ì¦ ë°©ì§€ìš©: ì „ì²´ êµì²´(ì‚­ì œ í›„ insert)
    """
    if supabase is None:
        st.error("âŒ Supabase ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    try:
        supabase.table("sales_data").delete().neq("id", 0).execute()

        df = df_upload.copy()
        for c in SALES_COLS:
            if c not in df.columns:
                df[c] = None

        df = fill_required_text(df, ["í’ˆë²ˆ", "ì»¬ëŸ¬", "ì œì¡°ë°©ì‹", "ì†Œì¬ëª…", "í•", "ê¸°ì¥"])
        for col in ["ê°€ê²©", "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

        df = make_json_safe_df(df)
        records = df[SALES_COLS].to_dict("records")
        if not records:
            st.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        supabase.table("sales_data").insert(records).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"íŒë§¤ ì „ì²´ êµì²´ ì‹¤íŒ¨: {e}")
        return False

def save_material_data(new_df: pd.DataFrame) -> bool:
    if supabase is None:
        st.error("âŒ Supabase ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    try:
        df = new_df.copy()
        for c in MATERIAL_COLS:
            if c not in df.columns:
                df[c] = None

        df = fill_required_text(df, ["ì†Œì¬ëª…"], default="UNKNOWN_MATERIAL")

        # ìˆ«ìí˜•: ì¤‘ëŸ‰/GU/RA/SAë§Œ
        for col in ["ì¤‘ëŸ‰", "GU", "RA", "SA"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")

        # í…ìŠ¤íŠ¸ ì •ë¦¬
        for tcol in ["ì†Œì¬ì—…ì²´", "í˜¼ìš©ì›ë‹¨", "í˜¼ìš©ìœ¨", "ì¡°ì§"]:
            if tcol in df.columns:
                df[tcol] = (
                    df[tcol].astype(str)
                    .replace(["None", "nan"], "")
                    .fillna("")
                    .apply(lambda x: x.strip())
                )

        df = make_json_safe_df(df)

        records = df[MATERIAL_COLS].to_dict("records")
        if not records:
            st.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        supabase.table("material_data").insert(records).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"ì†Œì¬ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def replace_material_data(df_upload: pd.DataFrame) -> bool:
    if supabase is None:
        st.error("âŒ Supabase ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    try:
        supabase.table("material_data").delete().neq("id", 0).execute()

        df = df_upload.copy()
        for c in MATERIAL_COLS:
            if c not in df.columns:
                df[c] = None

        df = fill_required_text(df, ["ì†Œì¬ëª…"], default="UNKNOWN_MATERIAL")
        for col in ["ì¤‘ëŸ‰", "GU", "RA", "SA"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")

        for tcol in ["ì†Œì¬ì—…ì²´", "í˜¼ìš©ì›ë‹¨", "í˜¼ìš©ìœ¨", "ì¡°ì§"]:
            if tcol in df.columns:
                df[tcol] = (
                    df[tcol].astype(str)
                    .replace(["None", "nan"], "")
                    .fillna("")
                    .apply(lambda x: x.strip())
                )

        df = make_json_safe_df(df)
        records = df[MATERIAL_COLS].to_dict("records")
        if not records:
            st.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        supabase.table("material_data").insert(records).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"ì†Œì¬ ì „ì²´ êµì²´ ì‹¤íŒ¨: {e}")
        return False

def delete_all_sales_data() -> bool:
    if supabase is None:
        return False
    try:
        supabase.table("sales_data").delete().neq("id", 0).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"íŒë§¤ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False

def delete_all_material_data() -> bool:
    if supabase is None:
        return False
    try:
        supabase.table("material_data").delete().neq("id", 0).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"ì†Œì¬ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False


# =========================
# í’ˆë²ˆ íŒŒì‹±/ë§¤í•‘
# =========================
def parse_item_code(code):
    if not code:
        return None
    code = str(code).strip()
    if len(code) < 8:
        return None
    try:
        return {
            "brand": code[0] if len(code) > 0 else None,
            "gender": code[1] if len(code) > 1 else None,
            "item_code": code[2:4] if len(code) >= 4 else None,
            "sequence": code[4:7] if len(code) >= 7 else None,
            "year": code[7] if len(code) >= 8 else None,
            "season": code[8] if len(code) >= 9 else None,
        }
    except Exception:
        return None

ITEM_MAPPING = {
    "DJ": "ë‹¤ìš´ì í¼", "DV": "ë‹¤ìš´ë² ìŠ¤íŠ¸", "JK": "ìì¼“", "JP": "ì í¼",
    "KC": "ë‹ˆíŠ¸ê°€ë””ê±´", "PD": "íŒ¨ë”©", "VT": "ë² ìŠ¤íŠ¸", "WJ": "ìœˆë“œë¸Œë ˆì´ì»¤", "WT": "ìš°ë¸í‹°ì…”ì¸ ",
    "HD": "í›„ë“œí‹°", "KP": "ìŠ¤ì›¨í„°í’€ì˜¤ë²„", "KV": "ìŠ¤ì›¨í„°ë² ìŠ¤íŠ¸", "KU": "ë°˜íŒ”ìŠ¤ì›¨í„°",
    "MT": "ë§¨íˆ¬ë§¨", "OP": "ì›í”¼ìŠ¤", "PQ": "í´ë¡œí‹°ì…”ì¸ ", "RL": "ê¸´íŒ”í‹°ì…”ì¸ ",
    "RS": "ë°˜íŒ”í‹°ì…”ì¸ ", "TR": "íŠ¸ë ˆì´ë‹ìƒì˜", "WS": "ìš°ë¸ì…”ì¸ ",
    "LG": "ë ˆê¹…ìŠ¤", "PT": "íŒ¬ì¸ ", "SK": "ìŠ¤ì»¤íŠ¸", "SP": "ë°˜ë°”ì§€",
    "SR": "ì—¬ì„±í•˜ì˜ìŠ¤ì½”íŠ¸", "TB": "íŠ¸ë ˆì´ë‹ìˆíŒ¬ì¸ ", "TP": "íŠ¸ë ˆì´ë‹í•˜ì˜",
    "BR": "ë¸Œë¼", "SL": "ìŠ¬ë¦¬ë¸Œë¦¬ìŠ¤",
}

CATEGORY_MAPPING = {
    "DJ": "ì•„ìš°í„°", "DV": "ì•„ìš°í„°", "JK": "ì•„ìš°í„°", "JP": "ì•„ìš°í„°", "KC": "ì•„ìš°í„°",
    "PD": "ì•„ìš°í„°", "VT": "ì•„ìš°í„°", "WJ": "ì•„ìš°í„°", "WT": "ì•„ìš°í„°",
    "HD": "ì´ë„ˆ", "KP": "ì´ë„ˆ", "KV": "ì´ë„ˆ", "KU": "ì´ë„ˆ", "MT": "ì´ë„ˆ",
    "OP": "ì´ë„ˆ", "PQ": "ì´ë„ˆ", "RL": "ì´ë„ˆ", "RS": "ì´ë„ˆ", "TR": "ì´ë„ˆ", "WS": "ì´ë„ˆ",
    "LG": "í•˜ì˜", "PT": "í•˜ì˜", "SK": "í•˜ì˜", "SP": "í•˜ì˜", "SR": "í•˜ì˜",
    "TB": "í•˜ì˜", "TP": "í•˜ì˜",
    "BR": "ê¸°íƒ€", "SL": "ê¸°íƒ€",
}

GENDER_MAPPING = {"M": "ë‚¨ì„±", "W": "ì—¬ì„±", "U": "ê³µìš©"}
SEASON_MAPPING = {"1": "ë´„", "3": "ì—¬ë¦„", "4": "ê°€ì„", "6": "ê²¨ìš¸"}
YEAR_MAPPING = {"3": "2023", "4": "2024", "5": "2025", "6": "2026"}

FIT_OPTIONS = ["slim", "regular", "semi-over", "over", "SLIM", "REGULAR", "SEMI-OVER", "OVER"]
LENGTH_OPTIONS = ["Crop", "Mid", "Long", "Regular", "Semi-Crop", "Short", "CROP", "MID", "LONG", "REGULAR", "SEMI-CROP", "SHORT"]
MANUFACTURING_OPTIONS = ["ì»·ì•¤ì†Œ", "ìš°ë¸", "ìŠ¤ì›¨í„°", "KNIT", "WOVEN", "CUT&SEW", "CUT-SEW"]

def enrich_sales_data(df: pd.DataFrame) -> pd.DataFrame:
    enriched = df.copy()
    parsed_data = []
    for _, row in enriched.iterrows():
        parsed = parse_item_code(row.get("í’ˆë²ˆ"))
        if parsed:
            parsed_data.append({
                "ì„±ë³„": GENDER_MAPPING.get(parsed["gender"], "ì•Œìˆ˜ì—†ìŒ"),
                "ì•„ì´í…œëª…": ITEM_MAPPING.get(parsed["item_code"], "ì•Œìˆ˜ì—†ìŒ"),
                "ì¹´í…Œê³ ë¦¬": CATEGORY_MAPPING.get(parsed["item_code"], "ê¸°íƒ€"),
                "ì—°ë„": YEAR_MAPPING.get(parsed["year"], "ì•Œìˆ˜ì—†ìŒ"),
                "ì‹œì¦Œ": SEASON_MAPPING.get(parsed["season"], "ì•Œìˆ˜ì—†ìŒ"),
            })
        else:
            parsed_data.append({
                "ì„±ë³„": "ì•Œìˆ˜ì—†ìŒ", "ì•„ì´í…œëª…": "ì•Œìˆ˜ì—†ìŒ",
                "ì¹´í…Œê³ ë¦¬": "ê¸°íƒ€", "ì—°ë„": "ì•Œìˆ˜ì—†ìŒ", "ì‹œì¦Œ": "ì•Œìˆ˜ì—†ìŒ"
            })
    return pd.concat([enriched.reset_index(drop=True), pd.DataFrame(parsed_data)], axis=1)


# =========================
# ì†Œì¬ ë§¤í•‘ ìœ í‹¸ (ì˜ˆì¸¡ ì…ë ¥ feature ê°•í™”)
# =========================
def get_material_row(material_name: str, mat_df: pd.DataFrame):
    if mat_df is None or mat_df.empty or not material_name:
        return None
    # ì†Œì¬ëª… exact ìš°ì„ , ì—†ìœ¼ë©´ trim ë¹„êµ
    m = mat_df[mat_df["ì†Œì¬ëª…"].astype(str).str.strip() == str(material_name).strip()]
    if not m.empty:
        return m.iloc[0].to_dict()
    m2 = mat_df[mat_df["ì†Œì¬ëª…"].astype(str).str.contains(str(material_name).strip(), na=False)]
    if not m2.empty:
        return m2.iloc[0].to_dict()
    return None


# =========================
# Session State ì´ˆê¸°í™”
# =========================
if "sales_data" not in st.session_state:
    st.session_state.sales_data = load_sales_data()
if "material_data" not in st.session_state:
    st.session_state.material_data = load_material_data()
if "ai_session_id" not in st.session_state:
    st.session_state.ai_session_id = None
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []


# =========================
# Sidebar / Menu
# =========================
st.sidebar.title("ğŸ‘” ì„¸ë¥´ì§€ì˜¤íƒ€í‚¤ë‹ˆ")
st.sidebar.markdown("### íŒë§¤ ë¶„ì„ ì‹œìŠ¤í…œ")

menu = st.sidebar.radio(
    "ë©”ë‰´",
    ["ğŸ¯ ì¡°í•© ì˜ˆì¸¡(AI)", "ğŸ“¥ ë°ì´í„° ì…ë ¥", "ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ† ë­í‚¹", "ğŸ§µ ì†Œì¬ ë¶„ì„", "ğŸ¤– AI ì¸ì‚¬ì´íŠ¸/ì±—ë´‡", "ğŸ’¾ ë°ì´í„° ê´€ë¦¬"]
)


# =========================
# 1) ì¡°í•© ì˜ˆì¸¡ (AI ê¸°ë°˜)
# =========================
if menu == "ğŸ¯ ì¡°í•© ì˜ˆì¸¡(AI)":
    st.title("ğŸ¯ ì¡°í•© ì˜ˆì¸¡ ì‹œë®¬ë ˆì´í„° (AI ê¸°ë°˜)")

    if requests is None:
        st.error("requests íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. requirements.txtì— requestsë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    elif st.session_state.sales_data.empty:
        st.warning("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë°ì´í„° ì…ë ¥'ì—ì„œ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        df_enriched = enrich_sales_data(st.session_state.sales_data)
        materials = sorted(df_enriched["ì†Œì¬ëª…"].dropna().unique().tolist())

        col1, col2 = st.columns(2)

        with col1:
            st.subheader("ğŸ“‹ ì¡°í•© ì…ë ¥ (ì˜ˆì¸¡ Feature ê°•í™”)")
            gender = st.selectbox("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±", "ê³µìš©"])
            item_name = st.selectbox("ì•„ì´í…œ", sorted(set(ITEM_MAPPING.values())))
            manufacturing = st.selectbox("ì œì¡°ë°©ì‹", MANUFACTURING_OPTIONS)

            material = st.selectbox("ì†Œì¬", materials) if materials else st.text_input("ì†Œì¬ëª… ì…ë ¥")
            fit = st.selectbox("í•", FIT_OPTIONS)
            length = st.selectbox("ê¸°ì¥", LENGTH_OPTIONS)

            # âœ… ì˜ˆì¸¡ ì •í™•ë„ í•µì‹¬ feature: ê°€ê²©
            # ìµœê·¼ ë°ì´í„°ì˜ ì¤‘ì•™ê°’ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì œì•ˆ
            default_price = int(df_enriched["ê°€ê²©"].median()) if "ê°€ê²©" in df_enriched.columns and len(df_enriched) else 0
            price = st.number_input("ê°€ê²©(ì˜ˆì¸¡ ì…ë ¥)", min_value=0, step=1000, value=default_price)

            # âœ… ì†Œì¬ë§ˆìŠ¤í„° ìë™ ë§¤í•‘(ì¡°ì§/GU/RA/SA/ì¤‘ëŸ‰/í˜¼ìš©ì •ë³´)
            mat_row = get_material_row(material, st.session_state.material_data)
            with st.expander("ğŸ§µ ì†Œì¬ ë§ˆìŠ¤í„° ë§¤í•‘(ìë™ ì…ë ¥) í™•ì¸", expanded=True):
                if mat_row:
                    st.write({
                        "ì¡°ì§": mat_row.get("ì¡°ì§"),
                        "GU": mat_row.get("GU"),
                        "RA": mat_row.get("RA"),
                        "SA": mat_row.get("SA"),
                        "ì¤‘ëŸ‰": mat_row.get("ì¤‘ëŸ‰"),
                        "í˜¼ìš©ì›ë‹¨": mat_row.get("í˜¼ìš©ì›ë‹¨"),
                        "í˜¼ìš©ìœ¨": mat_row.get("í˜¼ìš©ìœ¨"),
                        "ì†Œì¬ì—…ì²´": mat_row.get("ì†Œì¬ì—…ì²´"),
                    })
                else:
                    st.info("ì†Œì¬ ë§ˆìŠ¤í„°ì—ì„œ í•´ë‹¹ ì†Œì¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì˜ˆì¸¡ì€ ê°€ëŠ¥í•˜ì§€ë§Œ ì •í™•ë„ëŠ” ë‚®ì•„ì§ˆ ìˆ˜ ìˆìŒ)")

            predict_btn = st.button("ğŸ”® AI ì˜ˆì¸¡ ê²°ê³¼ ë³´ê¸°", type="primary", use_container_width=True)

        with col2:
            st.subheader("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼")
            if predict_btn:
                fn_predict = st.secrets.get("SUPABASE_FUNCTION_PREDICT_URL", "")
                if not fn_predict:
                    st.error("SUPABASE_FUNCTION_PREDICT_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    # íŒŒìƒ feature ìƒì„±
                    blend_feats = {}
                    if mat_row:
                        blend_feats = derive_blend_features(mat_row.get("í˜¼ìš©ì›ë‹¨"), mat_row.get("í˜¼ìš©ìœ¨"))
                    else:
                        blend_feats = {
                            "pct_cotton": None, "pct_synthetic": None, "pct_regenerated": None, "pct_spandex": None, "n_fibers": None
                        }

                    payload = {
                        # ê¸°ë³¸ ì¡°í•© feature
                        "gender": gender,
                        "item_name": item_name,
                        "manufacturing": manufacturing,
                        "material": material,
                        "fit": fit,
                        "length": length,

                        # âœ… ì˜ˆì¸¡ ì •í™•ë„ í•µì‹¬: ê°€ê²©
                        "price": float(price),

                        # âœ… ì†Œì¬ ë§ˆìŠ¤í„° feature(ìˆìœ¼ë©´ ì „ë‹¬)
                        "material_meta": {
                            "org": (mat_row.get("ì¡°ì§") if mat_row else None),
                            "gu": (mat_row.get("GU") if mat_row else None),
                            "ra": (mat_row.get("RA") if mat_row else None),
                            "sa": (mat_row.get("SA") if mat_row else None),
                            "weight": (mat_row.get("ì¤‘ëŸ‰") if mat_row else None),
                            "blend_fibers": (mat_row.get("í˜¼ìš©ì›ë‹¨") if mat_row else None),
                            "blend_ratio": (mat_row.get("í˜¼ìš©ìœ¨") if mat_row else None),
                            "supplier": (mat_row.get("ì†Œì¬ì—…ì²´") if mat_row else None),
                        },

                        # âœ… í˜¼ìš© íŒŒìƒ feature(ëª¨ë¸ ì„±ëŠ¥ì— ìœ ì˜ë¯¸)
                        "blend_features": blend_feats,
                    }

                    # ë§ˆì§€ë§‰ ì•ˆì „ì²˜ë¦¬(Inf/NaN ì œê±°)
                    def _clean(x):
                        if isinstance(x, float) and (np.isnan(x) or np.isinf(x)):
                            return None
                        return x

                    def _deep_clean(obj):
                        if isinstance(obj, dict):
                            return {k: _deep_clean(v) for k, v in obj.items()}
                        if isinstance(obj, list):
                            return [_deep_clean(v) for v in obj]
                        return _clean(obj)

                    payload = _deep_clean(payload)

                    out = None
                    try:
                        r = requests.post(fn_predict, json=payload, timeout=120)
                        out = safe_json(r)
                    except Exception as e:
                        st.error(f"AI ì˜ˆì¸¡ í˜¸ì¶œ ì‹¤íŒ¨: {e}")

                    if not isinstance(out, dict) or not out.get("ok"):
                        st.error(show_api_error(out))
                        st.caption("â€» Edge Functionì´ ì¶”ê°€ featureë¥¼ ì•„ì§ ì²˜ë¦¬í•˜ì§€ ì•Šì•„ë„, ê¸°ë³¸ featureë¡œ ì˜ˆì¸¡ì€ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
                    else:
                        res = out.get("result", {}) or {}
                        st.success("âœ… AI ì˜ˆì¸¡ ì™„ë£Œ")

                        c1, c2, c3 = st.columns(3)
                        c1.metric("ì˜ˆìƒ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", f"{float(res.get('pred_qty', 0)):.0f}ê°œ")
                        c2.metric("ì˜ˆìƒ ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", f"{float(res.get('pred_amt', 0)):,.0f}ì›")
                        c3.metric("ì‹ ë¢°ë„", f"{float(res.get('confidence', 0)):.0f}%")

                        st.markdown("#### ê·¼ê±°")
                        st.write(res.get("rationale", ""))

                        warnings = res.get("warnings", [])
                        if warnings:
                            st.warning(" / ".join(warnings))

                        # ë””ë²„ê·¸: ì‹¤ì œë¡œ ì–´ë–¤ featureë¥¼ ë³´ëƒˆëŠ”ì§€ í™•ì¸(ìš´ì˜ ì•ˆì •í™”ìš©)
                        with st.expander("ğŸ› ï¸ (ë””ë²„ê·¸) ì˜ˆì¸¡ ì…ë ¥ payload ë³´ê¸°", expanded=False):
                            st.json(payload)


# =========================
# 2) ë°ì´í„° ì…ë ¥
# =========================
elif menu == "ğŸ“¥ ë°ì´í„° ì…ë ¥":
    st.title("ğŸ“¥ ë°ì´í„° ì…ë ¥")

    tab1, tab2, tab3 = st.tabs(["ğŸ“ ìˆ˜ë™ ì…ë ¥", "ğŸ“‚ Excel ì—…ë¡œë“œ", "ğŸ§µ ì†Œì¬ ê´€ë¦¬"])

    with tab1:
        st.subheader("íŒë§¤ ë°ì´í„° ìˆ˜ë™ ì…ë ¥")
        st.info("ğŸ’¡ í…œí”Œë¦¿: í’ˆë²ˆ/ì»¬ëŸ¬/ê°€ê²©/ì œì¡°ë°©ì‹/ì†Œì¬ëª…/í•/ê¸°ì¥/ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰/ë‹¹ì‹œì¦ŒíŒë§¤ì•¡")

        col1, col2 = st.columns(2)
        with col1:
            input_code = st.text_input("í’ˆë²ˆ", placeholder="TXHD6054")
            input_color = st.text_input("ì»¬ëŸ¬", placeholder="BKS")
            input_price_unit = st.number_input("ê°€ê²©", min_value=0, step=1000, value=149000)
            input_manufacturing = st.text_input("ì œì¡°ë°©ì‹", value="KNIT")
            input_material = st.text_input("ì†Œì¬ëª…", placeholder="JZR3055 595ì®¸ë¦¬")

        with col2:
            input_fit = st.text_input("í•", value="REGULAR")
            input_length = st.text_input("ê¸°ì¥", value="REGULAR")
            input_qty = st.number_input("ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", min_value=0, step=1, value=15)

            auto_calc_amt = st.checkbox("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡ ìë™ ê³„ì‚°(ê°€ê²©Ã—ìˆ˜ëŸ‰)", value=True)
            if auto_calc_amt:
                input_amt = int(input_price_unit * input_qty)
                st.number_input("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", min_value=0, step=1000, value=input_amt, disabled=True)
            else:
                input_amt = st.number_input("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", min_value=0, step=1000, value=2235000)

        if st.button("â• íŒë§¤ ë°ì´í„° ì¶”ê°€", type="primary"):
            if input_code and input_color and input_material:
                new_row = pd.DataFrame([{
                    "í’ˆë²ˆ": input_code,
                    "ì»¬ëŸ¬": input_color,
                    "ê°€ê²©": int(input_price_unit),
                    "ì œì¡°ë°©ì‹": input_manufacturing,
                    "ì†Œì¬ëª…": input_material,
                    "í•": input_fit,
                    "ê¸°ì¥": input_length,
                    "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰": int(input_qty),
                    "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡": int(input_amt),
                }])
                if save_sales_data(new_row):
                    st.session_state.sales_data = load_sales_data()
                    st.success("âœ… ì¶”ê°€ ì™„ë£Œ!")
                    st.rerun()
            else:
                st.error("âŒ í’ˆë²ˆ, ì»¬ëŸ¬, ì†Œì¬ëª…ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")

    with tab2:
        st.subheader("Excel ì—…ë¡œë“œ (íŒë§¤ ë°ì´í„°)")

        template = pd.DataFrame(columns=SALES_COLS)
        template.loc[0] = ["TXHD6054", "BKS", 149000, "KNIT", "JZR3055 595ì®¸ë¦¬", "REGULAR", "REGULAR", 15, 2235000]

        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            template.to_excel(writer, index=False, sheet_name="íŒë§¤ë°ì´í„°")

        st.download_button(
            "ğŸ“¥ íŒë§¤ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            buffer.getvalue(),
            "íŒë§¤ë°ì´í„°_í…œí”Œë¦¿.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

        uploaded = st.file_uploader("íŒë§¤ Excel íŒŒì¼ ì„ íƒ", type=["xlsx", "xls"])
        if uploaded:
            try:
                df_upload = pd.read_excel(uploaded)
                df_upload = make_json_safe_df(df_upload)

                missing = [c for c in SALES_COLS if c not in df_upload.columns]
                if missing:
                    st.error(f"âŒ ì—…ë¡œë“œ íŒŒì¼ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
                else:
                    st.dataframe(df_upload.head(20), use_container_width=True)

                    colA, colB = st.columns(2)
                    with colA:
                        if st.button("âœ… íŒë§¤ ì—…ë¡œë“œ ì ìš©(ì¶”ê°€ Insert)"):
                            if save_sales_data(df_upload):
                                st.session_state.sales_data = load_sales_data()
                                st.success(f"âœ… {len(df_upload)}ê°œ ì¶”ê°€!")
                                st.rerun()

                    with colB:
                        if st.button("â™»ï¸ íŒë§¤ ì—…ë¡œë“œ ì ìš©(ì „ì²´ êµì²´)", help="ì¤‘ë³µ í­ì¦ ë°©ì§€: ê¸°ì¡´ íŒë§¤ ë°ì´í„° ì‚­ì œ í›„ ì—…ë¡œë“œë¡œ êµì²´"):
                            if replace_sales_data(df_upload):
                                st.session_state.sales_data = load_sales_data()
                                st.success(f"âœ… ì „ì²´ êµì²´ ì™„ë£Œ! ({len(df_upload)}ê°œ)")
                                st.rerun()

            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")

    with tab3:
        st.subheader("ì†Œì¬ ë§ˆìŠ¤í„° ê´€ë¦¬ (ë‘ê»˜ ì œê±° / ì¡°ì§ ì‚¬ìš©)")
        st.caption("âœ… í˜¼ìš©ìœ¨ì€ '24 / 76' ê°™ì€ ë¬¸ìì—´ë„ ê·¸ëŒ€ë¡œ ì €ì¥ë©ë‹ˆë‹¤.")

        template_mat = pd.DataFrame(columns=MATERIAL_COLS)
        template_mat.loc[0] = ["BF-5933", "BF", "POLYESTER", "100", 300, "INTERLOCK", 2, 1, 3]

        buffer2 = io.BytesIO()
        with pd.ExcelWriter(buffer2, engine="openpyxl") as writer:
            template_mat.to_excel(writer, index=False, sheet_name="ì†Œì¬ë°ì´í„°")

        st.download_button(
            "ğŸ“¥ ì†Œì¬ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            buffer2.getvalue(),
            "ì†Œì¬í…œí”Œë¦¿.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

        uploaded_mat = st.file_uploader("ì†Œì¬ Excel íŒŒì¼ ì„ íƒ", type=["xlsx", "xls"])
        if uploaded_mat:
            try:
                df_mat = pd.read_excel(uploaded_mat)
                df_mat = make_json_safe_df(df_mat)

                missing = [c for c in MATERIAL_COLS if c not in df_mat.columns]
                if missing:
                    st.error(f"âŒ ì—…ë¡œë“œ íŒŒì¼ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
                else:
                    st.dataframe(df_mat.head(30), use_container_width=True)

                    colA, colB = st.columns(2)
                    with colA:
                        if st.button("âœ… ì†Œì¬ ì—…ë¡œë“œ ì ìš©(ì¶”ê°€ Insert)"):
                            if save_material_data(df_mat):
                                st.session_state.material_data = load_material_data()
                                st.success("âœ… ì†Œì¬ ì¶”ê°€ ì™„ë£Œ!")
                                st.rerun()
                    with colB:
                        if st.button("â™»ï¸ ì†Œì¬ ì—…ë¡œë“œ ì ìš©(ì „ì²´ êµì²´)", help="ì¤‘ë³µ í­ì¦ ë°©ì§€: ê¸°ì¡´ ì†Œì¬ ë°ì´í„° ì‚­ì œ í›„ ì—…ë¡œë“œë¡œ êµì²´"):
                            if replace_material_data(df_mat):
                                st.session_state.material_data = load_material_data()
                                st.success("âœ… ì†Œì¬ ì „ì²´ êµì²´ ì™„ë£Œ!")
                                st.rerun()
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")


# =========================
# 3) ëŒ€ì‹œë³´ë“œ
# =========================
elif menu == "ğŸ“Š ëŒ€ì‹œë³´ë“œ":
    st.title("ğŸ“Š íŒë§¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)")

    if st.session_state.sales_data.empty:
        st.warning("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df = enrich_sales_data(st.session_state.sales_data.copy())

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ì´ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", f"{df['ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰'].sum():,}ê°œ")
        c2.metric("ì´ ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", f"{df['ë‹¹ì‹œì¦ŒíŒë§¤ì•¡'].sum():,}ì›")

        total_qty = df["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum()
        total_amt = df["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"].sum()
        avg_price = (total_amt / total_qty) if total_qty > 0 else 0
        c3.metric("í‰ê·  íŒë§¤ë‹¨ê°€(íŒë§¤ì•¡/ìˆ˜ëŸ‰)", f"{avg_price:,.0f}ì›")
        c4.metric("ì´ SKU", f"{len(df):,}ê°œ")

        st.divider()

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ‘¥ ì„±ë³„ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰")
            gender_sales = df.groupby("ì„±ë³„")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum()
            fig1 = px.pie(values=gender_sales.values, names=gender_sales.index, hole=0.4)
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            st.subheader("ğŸ­ ì œì¡°ë°©ì‹ë³„ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰")
            manu_sales = df.groupby("ì œì¡°ë°©ì‹")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum().sort_values(ascending=False)
            fig2 = px.bar(x=manu_sales.values, y=manu_sales.index, orientation="h")
            fig2.update_layout(showlegend=False, xaxis_title="ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", yaxis_title="")
            st.plotly_chart(fig2, use_container_width=True)


# =========================
# 4) ë­í‚¹
# =========================
elif menu == "ğŸ† ë­í‚¹":
    st.title("ğŸ† ì¡°í•©ë³„ ì„±ê³¼ ë­í‚¹ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)")

    if st.session_state.sales_data.empty:
        st.warning("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df = enrich_sales_data(st.session_state.sales_data.copy())
        df["ì¡°í•©"] = df["ì„±ë³„"] + " / " + df["ì•„ì´í…œëª…"] + " / " + df["ì œì¡°ë°©ì‹"] + " / " + df["ì†Œì¬ëª…"] + " / " + df["í•"] + " / " + df["ê¸°ì¥"]

        combo_stats = df.groupby("ì¡°í•©").agg({
            "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰": ["sum", "mean", "count"],
            "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡": ["sum", "mean"],
        }).round(0)

        combo_stats.columns = ["ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë°ì´í„°ìˆ˜", "ì´ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]
        combo_stats = combo_stats.reset_index()

        metric = st.radio("ë¶„ì„ ê¸°ì¤€", ["ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ì´ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"], horizontal=True)
        top_n = st.slider("í‘œì‹œí•  ì¡°í•© ìˆ˜", 5, 20, 10)

        col1, col2 = st.columns(2)
        with col1:
            st.subheader(f"ğŸ¥‡ Best {top_n}")
            top_combos = combo_stats.nlargest(top_n, metric)
            fig_top = px.bar(top_combos, x=metric, y="ì¡°í•©", orientation="h")
            fig_top.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig_top, use_container_width=True)
            st.dataframe(top_combos, use_container_width=True, hide_index=True)

        with col2:
            st.subheader(f"ğŸ¥‰ Worst {top_n}")
            bottom_combos = combo_stats.nsmallest(top_n, metric)
            fig_bottom = px.bar(bottom_combos, x=metric, y="ì¡°í•©", orientation="h")
            fig_bottom.update_layout(showlegend=False, yaxis={"categoryorder": "total descending"})
            st.plotly_chart(fig_bottom, use_container_width=True)
            st.dataframe(bottom_combos, use_container_width=True, hide_index=True)


# =========================
# 5) ì†Œì¬ ë¶„ì„ + ì¡°ì§ ë§¤íŠ¸ë¦­ìŠ¤
# =========================
elif menu == "ğŸ§µ ì†Œì¬ ë¶„ì„":
    st.title("ğŸ§µ ì†Œì¬ë³„ ì„±ê³¼ ë¶„ì„ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)")

    if st.session_state.sales_data.empty:
        st.warning("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df = enrich_sales_data(st.session_state.sales_data.copy())

        material_stats = df.groupby("ì†Œì¬ëª…").agg({
            "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰": ["sum", "mean", "count"],
            "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡": ["sum", "mean"],
            "í’ˆë²ˆ": "nunique",
        }).round(0)

        material_stats.columns = ["ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë°ì´í„°ìˆ˜", "ì´ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "SKUìˆ˜"]
        material_stats = material_stats.reset_index().sort_values("ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", ascending=False)

        st.subheader("ğŸ“Š ì†Œì¬ë³„ ì„±ê³¼ ìš”ì•½")
        st.dataframe(material_stats, use_container_width=True, hide_index=True)

        st.divider()
        st.subheader("ğŸ§¬ ì¡°ì§ Ã— GU/RA/SA Ã— íŒë§¤ ì„±ê³¼ ë§¤íŠ¸ë¦­ìŠ¤")

        if st.session_state.material_data.empty:
            st.warning("ì†Œì¬ ë§ˆìŠ¤í„°(material_data)ê°€ ë¹„ì–´ ìˆì–´ ì¡°ì§ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sales_df = st.session_state.sales_data.copy()
            mat_df = st.session_state.material_data.copy()

            sales_df["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"] = pd.to_numeric(sales_df["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"], errors="coerce").fillna(0)
            sales_df["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"] = pd.to_numeric(sales_df["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"], errors="coerce").fillna(0)

            for c in ["GU", "RA", "SA"]:
                if c in mat_df.columns:
                    mat_df[c] = pd.to_numeric(mat_df[c], errors="coerce")

            mat_small = mat_df[["ì†Œì¬ëª…", "ì¡°ì§", "GU", "RA", "SA"]].drop_duplicates(subset=["ì†Œì¬ëª…"])
            merged = sales_df.merge(mat_small, on="ì†Œì¬ëª…", how="left")

            miss_org = merged["ì¡°ì§"].isna().mean() if len(merged) else 1.0
            st.caption(f"ì¡°ì§ ë¯¸ë§¤ì¹­ ë¹„ìœ¨: **{miss_org*100:.1f}%**")

            matrix = (
                merged.dropna(subset=["ì¡°ì§"])
                .groupby("ì¡°ì§")
                .agg(
                    í‰ê· _GU=("GU", "mean"),
                    í‰ê· _RA=("RA", "mean"),
                    í‰ê· _SA=("SA", "mean"),
                    ì´íŒë§¤ìˆ˜ëŸ‰=("ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "sum"),
                    í‰ê· íŒë§¤ìˆ˜ëŸ‰=("ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "mean"),
                    ì´íŒë§¤ì•¡=("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "sum"),
                    SKUìˆ˜=("í’ˆë²ˆ", "nunique"),
                    ë°ì´í„°ìˆ˜=("í’ˆë²ˆ", "count"),
                )
                .reset_index()
            )

            for c in ["í‰ê· _GU", "í‰ê· _RA", "í‰ê· _SA", "í‰ê· íŒë§¤ìˆ˜ëŸ‰"]:
                matrix[c] = matrix[c].round(2)
            matrix["ì´íŒë§¤ì•¡"] = matrix["ì´íŒë§¤ì•¡"].fillna(0).astype(int)

            st.dataframe(
                matrix.sort_values("ì´íŒë§¤ìˆ˜ëŸ‰", ascending=False),
                use_container_width=True,
                hide_index=True
            )

            st.markdown("### ğŸ“Š ì¡°ì§ í¬ì§€ì…”ë‹ (SA Ã— GU, ë²„ë¸”=ì´íŒë§¤ìˆ˜ëŸ‰)")
            if not matrix.empty:
                fig = px.scatter(
                    matrix,
                    x="í‰ê· _SA",
                    y="í‰ê· _GU",
                    size="ì´íŒë§¤ìˆ˜ëŸ‰",
                    color="ì¡°ì§",
                    hover_name="ì¡°ì§",
                    size_max=60,
                    labels={"í‰ê· _SA": "SA(ë§¤ëˆí•¨)", "í‰ê· _GU": "GU(ê´‘íƒ)"}
                )
                fig.update_layout(xaxis_title="SA (ë§¤ëˆí•¨ â†‘)", yaxis_title="GU (ê´‘íƒ â†‘)")
                st.plotly_chart(fig, use_container_width=True)


# =========================
# 6) AI ì¸ì‚¬ì´íŠ¸/ì±—ë´‡ (Edge Function í˜¸ì¶œ)
# =========================
elif menu == "ğŸ¤– AI ì¸ì‚¬ì´íŠ¸/ì±—ë´‡":
    st.title("ğŸ¤– AI ì¸ì‚¬ì´íŠ¸ & Q&A ì±—ë´‡")

    if requests is None:
        st.error("requests íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. requirements.txtì— requestsë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
    elif supabase is None:
        st.error("Supabase ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        fn_url = st.secrets.get("SUPABASE_FUNCTION_INSIGHTS_URL", "")
        if not fn_url:
            st.warning("st.secretsì— SUPABASE_FUNCTION_INSIGHTS_URLì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        else:
            st.caption("â€» OpenAI KeyëŠ” Streamlitì´ ì•„ë‹ˆë¼ Supabase Edge Functionì—ë§Œ ì„¤ì •í•˜ì„¸ìš”(ë³´ì•ˆ).")

            col1, col2 = st.columns([1, 1])

            with col1:
                st.subheader("ğŸ“Œ ìë™ ì¸ì‚¬ì´íŠ¸ ìƒì„±")
                scope = st.text_input("ìŠ¤ì½”í”„(scope)", value="global", help="ì˜ˆ: global / org:INTERLOCK")
                if st.button("ğŸš€ ì¸ì‚¬ì´íŠ¸ ìƒì„±", type="primary", use_container_width=True):
                    try:
                        r = requests.post(fn_url, json={"mode": "insight", "scope": scope}, timeout=120)
                        out = safe_json(r)
                        if isinstance(out, dict) and out.get("ok"):
                            st.success("ìƒì„± ì™„ë£Œ")
                            st.markdown(out.get("insight", ""))
                        else:
                            st.error(show_api_error(out, "Unknown error"))
                    except Exception as e:
                        st.error(f"í˜¸ì¶œ ì‹¤íŒ¨: {e}")

            with col2:
                st.subheader("ğŸ’¬ ì¶”ê°€ ì§ˆì˜ì‘ë‹µ(ì±—ë´‡)")
                q = st.text_area("ì§ˆë¬¸", placeholder="ì˜ˆ: INTERLOCK ì¡°ì§ì€ SAê°€ ë†’ì€ë° íŒë§¤ê°€ ì™œ ë‚®ì•„? ë‹¤ìŒ ì‹œì¦Œ í…ŒìŠ¤íŠ¸ëŠ”?")
                if st.button("ì§ˆë¬¸í•˜ê¸°", use_container_width=True):
                    if not q.strip():
                        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    else:
                        try:
                            # ìµœê·¼ Ní„´ë§Œ ìœ ì§€(ë ‰ ë°©ì§€)
                            st.session_state.chat_log = st.session_state.chat_log[-20:]

                            payload = {
                                "mode": "chat",
                                "scope": scope,
                                "session_id": st.session_state.ai_session_id,
                                "question": q.strip(),
                            }
                            r = requests.post(fn_url, json=payload, timeout=120)
                            out = safe_json(r)
                            if isinstance(out, dict) and out.get("ok"):
                                st.session_state.ai_session_id = out.get("session_id")
                                answer = out.get("answer", "")
                                st.session_state.chat_log.append(("Q", q.strip()))
                                st.session_state.chat_log.append(("A", answer))
                            else:
                                st.error(show_api_error(out, "Unknown error"))
                        except Exception as e:
                            st.error(f"í˜¸ì¶œ ì‹¤íŒ¨: {e}")

                # ë¡œê·¸ í‘œì‹œ
                if st.session_state.chat_log:
                    st.divider()
                    for role, text in st.session_state.chat_log[-20:]:
                        if role == "Q":
                            st.markdown(f"**Q:** {text}")
                        else:
                            st.markdown(f"**A:** {text}")


# =========================
# 7) ë°ì´í„° ê´€ë¦¬
# =========================
elif menu == "ğŸ’¾ ë°ì´í„° ê´€ë¦¬":
    st.title("ğŸ’¾ ë°ì´í„° ê´€ë¦¬")

    tab1, tab2, tab3 = st.tabs(["ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", "ğŸ“Š ë°ì´í„° í™•ì¸/í¸ì§‘", "ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ"])

    with tab1:
        st.subheader("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### íŒë§¤ ë°ì´í„°")
            if not st.session_state.sales_data.empty:
                buffer1 = io.BytesIO()
                with pd.ExcelWriter(buffer1, engine="openpyxl") as writer:
                    st.session_state.sales_data[SALES_COLS].to_excel(writer, index=False, sheet_name="íŒë§¤ë°ì´í„°")
                st.download_button(
                    "ğŸ“¥ íŒë§¤ ë°ì´í„° Excel ë‹¤ìš´ë¡œë“œ",
                    buffer1.getvalue(),
                    f"íŒë§¤ë°ì´í„°_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.info("ë‹¤ìš´ë¡œë“œí•  íŒë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with col2:
            st.markdown("#### ì†Œì¬ ë°ì´í„°")
            if not st.session_state.material_data.empty:
                buffer2 = io.BytesIO()
                with pd.ExcelWriter(buffer2, engine="openpyxl") as writer:
                    st.session_state.material_data[MATERIAL_COLS].to_excel(writer, index=False, sheet_name="ì†Œì¬ë°ì´í„°")
                st.download_button(
                    "ğŸ“¥ ì†Œì¬ ë°ì´í„° Excel ë‹¤ìš´ë¡œë“œ",
                    buffer2.getvalue(),
                    f"ì†Œì¬ë°ì´í„°_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.info("ë‹¤ìš´ë¡œë“œí•  ì†Œì¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab2:
        st.subheader("ğŸ“Š ë°ì´í„° í™•ì¸/í¸ì§‘ (ê°„ë‹¨ í¸ì§‘)")
        st.caption("âš ï¸ í¸ì§‘ í›„ ì €ì¥ì€ 'ì „ì²´ êµì²´' ë°©ì‹ìœ¼ë¡œ ë°˜ì˜ë©ë‹ˆë‹¤(ì¤‘ë³µ/ë¶ˆì¼ì¹˜ ë°©ì§€).")

        st.markdown("#### íŒë§¤ ë°ì´í„° í¸ì§‘")
        df_edit_sales = st.data_editor(
            st.session_state.sales_data[SALES_COLS].copy(),
            use_container_width=True,
            num_rows="dynamic",
            key="editor_sales"
        )
        if st.button("ğŸ’¾ íŒë§¤ í¸ì§‘ ë‚´ìš© ì €ì¥(ì „ì²´ êµì²´)", type="primary"):
            if replace_sales_data(df_edit_sales):
                st.session_state.sales_data = load_sales_data()
                st.success("âœ… íŒë§¤ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
                st.rerun()

        st.divider()

        st.markdown("#### ì†Œì¬ ë°ì´í„° í¸ì§‘")
        df_edit_mat = st.data_editor(
            st.session_state.material_data[MATERIAL_COLS].copy(),
            use_container_width=True,
            num_rows="dynamic",
            key="editor_mat"
        )
        if st.button("ğŸ’¾ ì†Œì¬ í¸ì§‘ ë‚´ìš© ì €ì¥(ì „ì²´ êµì²´)", type="primary"):
            if replace_material_data(df_edit_mat):
                st.session_state.material_data = load_material_data()
                st.success("âœ… ì†Œì¬ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
                st.rerun()

    with tab3:
        st.subheader("ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ")
        st.warning("âš ï¸ **ì£¼ì˜**: ì‚­ì œëœ ë°ì´í„°ëŠ” ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ë¨¼ì € ë°±ì—…ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
        c1, c2 = st.columns(2)
        with c1:
            if st.button("ğŸ—‘ï¸ íŒë§¤ ë°ì´í„° ì „ì²´ ì‚­ì œ", type="secondary"):
                if delete_all_sales_data():
                    st.session_state.sales_data = load_sales_data()
                    st.success("âœ… íŒë§¤ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
        with c2:
            if st.button("ğŸ—‘ï¸ ì†Œì¬ ë°ì´í„° ì „ì²´ ì‚­ì œ", type="secondary"):
                if delete_all_material_data():
                    st.session_state.material_data = load_material_data()
                    st.success("âœ… ì†Œì¬ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()


# =========================
# Footer
# =========================
st.sidebar.divider()
st.sidebar.info(f"""
ğŸ“Š **í˜„ì¬ ë°ì´í„° í˜„í™©**
- íŒë§¤ ë°ì´í„°: {len(st.session_state.sales_data)}ê±´
- ì†Œì¬ ë°ì´í„°: {len(st.session_state.material_data)}ê±´

ğŸ”„ **ìºì‹œ**
- ìºì‹œ ì‹œê°„: 10ë¶„
""")
st.sidebar.caption("Â© 2025 ì„¸ë¥´ì§€ì˜¤íƒ€í‚¤ë‹ˆ íŒë§¤ë¶„ì„ì‹œìŠ¤í…œ (Streamlit+Supabase)")
