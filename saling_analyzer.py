# app.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from datetime import datetime
import io
from supabase import create_client, Client

# =========================
# í˜ì´ì§€ ì„¤ì •
# =========================
st.set_page_config(
    page_title="ì„¸ë¥´ì§€ì˜¤íƒ€í‚¤ë‹ˆ íŒë§¤ ë¶„ì„",
    page_icon="ğŸ‘”",
    layout="wide"
)

# =========================
# í…œí”Œë¦¿ ì»¬ëŸ¼ ì •ì˜ (ì‹ ê·œ)
# =========================
SALES_COLS = ["í’ˆë²ˆ", "ì»¬ëŸ¬", "ê°€ê²©", "ì œì¡°ë°©ì‹", "ì†Œì¬ëª…", "í•", "ê¸°ì¥", "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]
MATERIAL_COLS = ["ì†Œì¬ëª…", "ì†Œì¬ì—…ì²´", "í˜¼ìš©ì›ë‹¨", "í˜¼ìš©ìœ¨", "ì¤‘ëŸ‰", "ë‘ê»˜", "ë°€ë„", "GU", "RA", "SA"]

# =========================
# Supabase ì—°ê²°
# =========================
@st.cache_resource
def init_supabase():
    try:
        url = st.secrets["SUPABASE_URL"]
        key = st.secrets["SUPABASE_KEY"]
        return create_client(url, key)
    except Exception as e:
        st.error(f"âŒ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

supabase: Client = init_supabase()

# =========================
# ìœ í‹¸: JSON-safe ë³€í™˜ (NaN/Inf ì œê±°)
# =========================
def make_json_safe_df(df: pd.DataFrame) -> pd.DataFrame:
    """Supabase insert(JSON)ì—ì„œ í„°ì§€ëŠ” NaN/Infë¥¼ Noneìœ¼ë¡œ ì¹˜í™˜"""
    if df is None or df.empty:
        return df
    out = df.copy()
    out = out.replace([np.nan, np.inf, -np.inf], None)
    return out

# =========================
# ìœ í‹¸: ìƒê´€/êµ¬ê°„ ë¶„ì„
# =========================
def _bin_series(s: pd.Series, method="equal_width", bins=4):
    s = pd.to_numeric(s, errors="coerce")
    s = s.replace([np.inf, -np.inf], np.nan).dropna()
    if s.empty:
        return None
    if method == "quantile":
        return pd.qcut(s, q=bins, duplicates="drop")
    return pd.cut(s, bins=bins)

def _safe_corr(a: pd.Series, b: pd.Series):
    a = pd.to_numeric(a, errors="coerce")
    b = pd.to_numeric(b, errors="coerce")
    df2 = pd.concat([a, b], axis=1).dropna()
    if len(df2) < 3:
        return np.nan
    return df2.iloc[:, 0].corr(df2.iloc[:, 1])

# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
@st.cache_data(ttl=600)
def load_sales_data():
    if supabase is None:
        return pd.DataFrame(columns=SALES_COLS)
    try:
        res = supabase.table("sales_data").select("*").execute()
        if res.data:
            df = pd.DataFrame(res.data)
            for c in SALES_COLS:
                if c not in df.columns:
                    df[c] = None
            df = df[SALES_COLS].copy()
            for col in ["ê°€ê²©", "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
            return df
        return pd.DataFrame(columns=SALES_COLS)
    except Exception as e:
        st.error(f"íŒë§¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(columns=SALES_COLS)

@st.cache_data(ttl=600)
def load_material_data():
    if supabase is None:
        return pd.DataFrame(columns=MATERIAL_COLS)
    try:
        res = supabase.table("material_data").select("*").execute()
        if res.data:
            df = pd.DataFrame(res.data)
            for c in MATERIAL_COLS:
                if c not in df.columns:
                    df[c] = None
            df = df[MATERIAL_COLS].copy()
            for col in ["í˜¼ìš©ìœ¨", "ì¤‘ëŸ‰", "ë°€ë„", "GU", "RA", "SA"]:
                df[col] = pd.to_numeric(df[col], errors="coerce")
            df["ë‘ê»˜"] = df["ë‘ê»˜"].astype(str)
            return df
        return pd.DataFrame(columns=MATERIAL_COLS)
    except Exception as e:
        st.error(f"ì†Œì¬ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(columns=MATERIAL_COLS)

# =========================
# ë°ì´í„° ì €ì¥/ì‚­ì œ
# =========================
def save_sales_data(new_df: pd.DataFrame) -> bool:
    if supabase is None:
        st.error("âŒ Supabase ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    try:
        df = new_df.copy()

        # ì»¬ëŸ¼ ë³´ì •
        for c in SALES_COLS:
            if c not in df.columns:
                df[c] = None

        # ìˆ«ìí˜• ë³´ì •
        for col in ["ê°€ê²©", "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

        # âœ… JSON-safe (NaN/Inf ì œê±°)  â† (ê¸°ì¡´ ì½”ë“œì—ì„œ ë“¤ì—¬ì“°ê¸° ê¹¨ì ¸ SyntaxError ì›ì¸)
        df = make_json_safe_df(df)

        records = df[SALES_COLS].to_dict("records")
        if not records:
            st.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        supabase.table("sales_data").insert(records).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"íŒë§¤ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_material_data(new_df: pd.DataFrame) -> bool:
    if supabase is None:
        st.error("âŒ Supabase ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    try:
        df = new_df.copy()

        for c in MATERIAL_COLS:
            if c not in df.columns:
                df[c] = None

        for col in ["í˜¼ìš©ìœ¨", "ì¤‘ëŸ‰", "ë°€ë„", "GU", "RA", "SA"]:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

        df["ë‘ê»˜"] = df["ë‘ê»˜"].astype(str)

        # âœ… JSON-safe
        df = make_json_safe_df(df)

        records = df[MATERIAL_COLS].to_dict("records")
        if not records:
            st.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        supabase.table("material_data").insert(records).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"ì†Œì¬ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def delete_all_sales_data() -> bool:
    if supabase is None:
        return False
    try:
        supabase.table("sales_data").delete().neq("id", 0).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"íŒë§¤ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False

def delete_all_material_data() -> bool:
    if supabase is None:
        return False
    try:
        supabase.table("material_data").delete().neq("id", 0).execute()
        st.cache_data.clear()
        return True
    except Exception as e:
        st.error(f"ì†Œì¬ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False

# =========================
# í’ˆë²ˆ íŒŒì‹±/ë§¤í•‘
# =========================
def parse_item_code(code):
    if not code:
        return None
    code = str(code).strip()
    if len(code) < 8:
        return None
    try:
        return {
            "brand": code[0] if len(code) > 0 else None,
            "gender": code[1] if len(code) > 1 else None,
            "item_code": code[2:4] if len(code) >= 4 else None,
            "sequence": code[4:7] if len(code) >= 7 else None,
            "year": code[7] if len(code) >= 8 else None,
            "season": code[8] if len(code) >= 9 else None,
        }
    except Exception:
        return None

ITEM_MAPPING = {
    "DJ": "ë‹¤ìš´ì í¼", "DV": "ë‹¤ìš´ë² ìŠ¤íŠ¸", "JK": "ìì¼“", "JP": "ì í¼",
    "KC": "ë‹ˆíŠ¸ê°€ë””ê±´", "PD": "íŒ¨ë”©", "VT": "ë² ìŠ¤íŠ¸", "WJ": "ìœˆë“œë¸Œë ˆì´ì»¤", "WT": "ìš°ë¸í‹°ì…”ì¸ ",
    "HD": "í›„ë“œí‹°", "KP": "ìŠ¤ì›¨í„°í’€ì˜¤ë²„", "KV": "ìŠ¤ì›¨í„°ë² ìŠ¤íŠ¸", "KU": "ë°˜íŒ”ìŠ¤ì›¨í„°",
    "MT": "ë§¨íˆ¬ë§¨", "OP": "ì›í”¼ìŠ¤", "PQ": "í´ë¡œí‹°ì…”ì¸ ", "RL": "ê¸´íŒ”í‹°ì…”ì¸ ",
    "RS": "ë°˜íŒ”í‹°ì…”ì¸ ", "TR": "íŠ¸ë ˆì´ë‹ìƒì˜", "WS": "ìš°ë¸ì…”ì¸ ",
    "LG": "ë ˆê¹…ìŠ¤", "PT": "íŒ¬ì¸ ", "SK": "ìŠ¤ì»¤íŠ¸", "SP": "ë°˜ë°”ì§€",
    "SR": "ì—¬ì„±í•˜ì˜ìŠ¤ì½”íŠ¸", "TB": "íŠ¸ë ˆì´ë‹ìˆíŒ¬ì¸ ", "TP": "íŠ¸ë ˆì´ë‹í•˜ì˜",
    "BR": "ë¸Œë¼", "SL": "ìŠ¬ë¦¬ë¸Œë¦¬ìŠ¤",
}

CATEGORY_MAPPING = {
    "DJ": "ì•„ìš°í„°", "DV": "ì•„ìš°í„°", "JK": "ì•„ìš°í„°", "JP": "ì•„ìš°í„°", "KC": "ì•„ìš°í„°",
    "PD": "ì•„ìš°í„°", "VT": "ì•„ìš°í„°", "WJ": "ì•„ìš°í„°", "WT": "ì•„ìš°í„°",
    "HD": "ì´ë„ˆ", "KP": "ì´ë„ˆ", "KV": "ì´ë„ˆ", "KU": "ì´ë„ˆ", "MT": "ì´ë„ˆ",
    "OP": "ì´ë„ˆ", "PQ": "ì´ë„ˆ", "RL": "ì´ë„ˆ", "RS": "ì´ë„ˆ", "TR": "ì´ë„ˆ", "WS": "ì´ë„ˆ",
    "LG": "í•˜ì˜", "PT": "í•˜ì˜", "SK": "í•˜ì˜", "SP": "í•˜ì˜", "SR": "í•˜ì˜",
    "TB": "í•˜ì˜", "TP": "í•˜ì˜",
    "BR": "ê¸°íƒ€", "SL": "ê¸°íƒ€",
}

GENDER_MAPPING = {"M": "ë‚¨ì„±", "W": "ì—¬ì„±", "U": "ê³µìš©"}
SEASON_MAPPING = {"1": "ë´„", "3": "ì—¬ë¦„", "4": "ê°€ì„", "6": "ê²¨ìš¸"}
YEAR_MAPPING = {"3": "2023", "4": "2024", "5": "2025", "6": "2026"}

FIT_OPTIONS = ["slim", "regular", "semi-over", "over", "SLIM", "REGULAR", "SEMI-OVER", "OVER"]
LENGTH_OPTIONS = ["Crop", "Mid", "Long", "Regular", "Semi-Crop", "Short", "CROP", "MID", "LONG", "REGULAR", "SEMI-CROP", "SHORT"]
MANUFACTURING_OPTIONS = ["ì»·ì•¤ì†Œ", "ìš°ë¸", "ìŠ¤ì›¨í„°", "KNIT", "WOVEN", "CUT&SEW", "CUT-SEW"]

def enrich_sales_data(df: pd.DataFrame) -> pd.DataFrame:
    enriched = df.copy()
    parsed_data = []
    for _, row in enriched.iterrows():
        parsed = parse_item_code(row.get("í’ˆë²ˆ"))
        if parsed:
            parsed_data.append({
                "ì„±ë³„": GENDER_MAPPING.get(parsed["gender"], "ì•Œìˆ˜ì—†ìŒ"),
                "ì•„ì´í…œëª…": ITEM_MAPPING.get(parsed["item_code"], "ì•Œìˆ˜ì—†ìŒ"),
                "ì¹´í…Œê³ ë¦¬": CATEGORY_MAPPING.get(parsed["item_code"], "ê¸°íƒ€"),
                "ì—°ë„": YEAR_MAPPING.get(parsed["year"], "ì•Œìˆ˜ì—†ìŒ"),
                "ì‹œì¦Œ": SEASON_MAPPING.get(parsed["season"], "ì•Œìˆ˜ì—†ìŒ"),
            })
        else:
            parsed_data.append({
                "ì„±ë³„": "ì•Œìˆ˜ì—†ìŒ", "ì•„ì´í…œëª…": "ì•Œìˆ˜ì—†ìŒ",
                "ì¹´í…Œê³ ë¦¬": "ê¸°íƒ€", "ì—°ë„": "ì•Œìˆ˜ì—†ìŒ", "ì‹œì¦Œ": "ì•Œìˆ˜ì—†ìŒ"
            })
    return pd.concat([enriched.reset_index(drop=True), pd.DataFrame(parsed_data)], axis=1)

# =========================
# ì˜ˆì¸¡ ë¡œì§ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)
# =========================
def predict_combination(gender, item_name, manufacturing, material, fit, length):
    if st.session_state.sales_data.empty:
        return None

    df = enrich_sales_data(st.session_state.sales_data)

    exact = df[
        (df["ì„±ë³„"] == gender) &
        (df["ì•„ì´í…œëª…"] == item_name) &
        (df["ì œì¡°ë°©ì‹"] == manufacturing) &
        (df["ì†Œì¬ëª…"] == material) &
        (df["í•"] == fit) &
        (df["ê¸°ì¥"] == length)
    ]
    if not exact.empty:
        return {
            "type": "exact",
            "avg_quantity": exact["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].mean(),
            "avg_price": exact["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"].mean(),
            "count": len(exact),
            "confidence": 95
        }

    similar = df[
        (df["ì„±ë³„"] == gender) &
        (df["ì•„ì´í…œëª…"] == item_name) &
        (df["ì œì¡°ë°©ì‹"] == manufacturing) &
        (df["ì†Œì¬ëª…"] == material) &
        (df["í•"] == fit)
    ]
    if not similar.empty:
        return {"type": "similar_5",
                "avg_quantity": similar["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].mean(),
                "avg_price": similar["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"].mean(),
                "count": len(similar),
                "confidence": 80}

    similar = df[
        (df["ì„±ë³„"] == gender) &
        (df["ì•„ì´í…œëª…"] == item_name) &
        (df["ì œì¡°ë°©ì‹"] == manufacturing) &
        (df["ì†Œì¬ëª…"] == material)
    ]
    if not similar.empty:
        return {"type": "similar_4",
                "avg_quantity": similar["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].mean(),
                "avg_price": similar["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"].mean(),
                "count": len(similar),
                "confidence": 65}

    similar = df[
        (df["ì„±ë³„"] == gender) &
        (df["ì•„ì´í…œëª…"] == item_name) &
        (df["ì œì¡°ë°©ì‹"] == manufacturing)
    ]
    if not similar.empty:
        return {"type": "similar_3",
                "avg_quantity": similar["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].mean(),
                "avg_price": similar["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"].mean(),
                "count": len(similar),
                "confidence": 45}

    return None

# =========================
# Session State ì´ˆê¸°í™”
# =========================
if "sales_data" not in st.session_state:
    st.session_state.sales_data = load_sales_data()
if "material_data" not in st.session_state:
    st.session_state.material_data = load_material_data()

# =========================
# Sidebar / Menu
# =========================
st.sidebar.title("ğŸ‘” ì„¸ë¥´ì§€ì˜¤íƒ€í‚¤ë‹ˆ")
st.sidebar.markdown("### íŒë§¤ ë¶„ì„ ì‹œìŠ¤í…œ")

menu = st.sidebar.radio(
    "ë©”ë‰´",
    ["ğŸ¯ ì¡°í•© ì˜ˆì¸¡", "ğŸ“¥ ë°ì´í„° ì…ë ¥", "ğŸ“Š ëŒ€ì‹œë³´ë“œ", "ğŸ† ë­í‚¹", "ğŸ§µ ì†Œì¬ ë¶„ì„", "ğŸ’¾ ë°ì´í„° ê´€ë¦¬"]
)

# =========================
# 1) ì¡°í•© ì˜ˆì¸¡
# =========================
if menu == "ğŸ¯ ì¡°í•© ì˜ˆì¸¡":
    st.title("ğŸ¯ ì¡°í•© ì˜ˆì¸¡ ì‹œë®¬ë ˆì´í„° (ë‹¹ì‹œì¦Œ ê¸°ì¤€)")

    if st.session_state.sales_data.empty:
        st.warning("âš ï¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'ë°ì´í„° ì…ë ¥'ì—ì„œ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ“‹ ì¡°í•© ì…ë ¥")
            gender = st.selectbox("ì„±ë³„", ["ë‚¨ì„±", "ì—¬ì„±", "ê³µìš©"])
            item_name = st.selectbox("ì•„ì´í…œ", sorted(set(ITEM_MAPPING.values())))
            manufacturing = st.selectbox("ì œì¡°ë°©ì‹", MANUFACTURING_OPTIONS)

            df_enriched = enrich_sales_data(st.session_state.sales_data)
            materials = sorted(df_enriched["ì†Œì¬ëª…"].dropna().unique().tolist())
            material = st.selectbox("ì†Œì¬", materials) if materials else st.text_input("ì†Œì¬ëª… ì…ë ¥")

            fit = st.selectbox("í•", FIT_OPTIONS)
            length = st.selectbox("ê¸°ì¥", LENGTH_OPTIONS)

            predict_btn = st.button("ğŸ”® ì˜ˆì¸¡ ê²°ê³¼ ë³´ê¸°", type="primary", use_container_width=True)

        with col2:
            st.subheader("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼")
            if predict_btn:
                result = predict_combination(gender, item_name, manufacturing, material, fit, length)
                if result:
                    st.success("âœ… ì˜ˆì¸¡ ì™„ë£Œ!")
                    c1, c2, c3 = st.columns(3)
                    c1.metric("ì˜ˆìƒ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", f"{result['avg_quantity']:.0f}ê°œ")
                    c2.metric("ì˜ˆìƒ ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", f"{result['avg_price']:,.0f}ì›")
                    c3.metric("ì‹ ë¢°ë„", f"{result['confidence']}%")
                    st.divider()
                    label = {
                        "exact": "âœ¨ ì™„ì „ ì¼ì¹˜",
                        "similar_5": "ğŸ“Œ ìœ ì‚¬ ì¡°í•©(5ê°œ ì¼ì¹˜)",
                        "similar_4": "âš ï¸ ë¶€ë¶„ ì¼ì¹˜(4ê°œ)",
                        "similar_3": "âš ï¸ ë‚®ì€ ì‹ ë¢°ë„(3ê°œ)"
                    }.get(result["type"], result["type"])
                    st.info(f"{label}: {result['count']}ê±´ ê¸°ë°˜")
                else:
                    st.error("âŒ ì°¸ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# =========================
# 2) ë°ì´í„° ì…ë ¥
# =========================
elif menu == "ğŸ“¥ ë°ì´í„° ì…ë ¥":
    st.title("ğŸ“¥ ë°ì´í„° ì…ë ¥ (ì‹ ê·œ í…œí”Œë¦¿)")

    tab1, tab2, tab3 = st.tabs(["ğŸ“ ìˆ˜ë™ ì…ë ¥", "ğŸ“‚ Excel ì—…ë¡œë“œ", "ğŸ§µ ì†Œì¬ ê´€ë¦¬"])

    with tab1:
        st.subheader("íŒë§¤ ë°ì´í„° ìˆ˜ë™ ì…ë ¥")
        st.info("ğŸ’¡ ì‹ ê·œ í…œí”Œë¦¿: í’ˆë²ˆ/ì»¬ëŸ¬/ê°€ê²©/ì œì¡°ë°©ì‹/ì†Œì¬ëª…/í•/ê¸°ì¥/ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰/ë‹¹ì‹œì¦ŒíŒë§¤ì•¡")

        col1, col2 = st.columns(2)
        with col1:
            input_code = st.text_input("í’ˆë²ˆ", placeholder="TXHD6054")
            if input_code:
                parsed = parse_item_code(input_code)
                if parsed:
                    gender_text = GENDER_MAPPING.get(parsed["gender"], "ì•Œìˆ˜ì—†ìŒ")
                    item_text = ITEM_MAPPING.get(parsed["item_code"], "ì•Œìˆ˜ì—†ìŒ")
                    st.success(f"âœ… {gender_text} / {item_text}")
                else:
                    st.warning("âš ï¸ í’ˆë²ˆ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš” (ìµœì†Œ 8ìë¦¬)")

            input_color = st.text_input("ì»¬ëŸ¬", placeholder="BKS")
            input_price_unit = st.number_input("ê°€ê²©", min_value=0, step=1000, value=149000)
            input_manufacturing = st.text_input("ì œì¡°ë°©ì‹", value="KNIT", help="ì˜ˆ: KNIT / WOVEN / CUT&SEW")
            input_material = st.text_input("ì†Œì¬ëª…", placeholder="JZR3055 595ì®¸ë¦¬")

        with col2:
            input_fit = st.text_input("í•", value="SEMI-OVER")
            input_length = st.text_input("ê¸°ì¥", value="REGULAR")
            input_qty = st.number_input("ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", min_value=0, step=1, value=15)

            auto_calc_amt = st.checkbox("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡ ìë™ ê³„ì‚°(ê°€ê²©Ã—ìˆ˜ëŸ‰)", value=True)
            if auto_calc_amt:
                input_amt = int(input_price_unit * input_qty)
                st.number_input("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", min_value=0, step=1000, value=input_amt, disabled=True)
            else:
                input_amt = st.number_input("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", min_value=0, step=1000, value=2235000)

        if st.button("â• íŒë§¤ ë°ì´í„° ì¶”ê°€", type="primary"):
            if input_code and input_color and input_material:
                new_row = pd.DataFrame([{
                    "í’ˆë²ˆ": input_code,
                    "ì»¬ëŸ¬": input_color,
                    "ê°€ê²©": int(input_price_unit),
                    "ì œì¡°ë°©ì‹": input_manufacturing,
                    "ì†Œì¬ëª…": input_material,
                    "í•": input_fit,
                    "ê¸°ì¥": input_length,
                    "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰": int(input_qty),
                    "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡": int(input_amt),
                }])
                if save_sales_data(new_row):
                    st.session_state.sales_data = load_sales_data()
                    st.success("âœ… ì¶”ê°€ ì™„ë£Œ!")
                    st.rerun()
            else:
                st.error("âŒ í’ˆë²ˆ, ì»¬ëŸ¬, ì†Œì¬ëª…ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")

    with tab2:
        st.subheader("Excel ì—…ë¡œë“œ (íŒë§¤ ë°ì´í„°)")

        template = pd.DataFrame(columns=SALES_COLS)
        template.loc[0] = ["TXHD6054", "BKS", 149000, "KNIT", "JZR3055 595ì®¸ë¦¬", "SEMI-OVER", "REGULAR", 15, 2235000]

        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            template.to_excel(writer, index=False, sheet_name="íŒë§¤ë°ì´í„°")

        st.download_button(
            "ğŸ“¥ íŒë§¤ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            buffer.getvalue(),
            "íŒë§¤ë°ì´í„°_í…œí”Œë¦¿_ì‹ ê·œ.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

        uploaded = st.file_uploader("íŒë§¤ Excel íŒŒì¼ ì„ íƒ", type=["xlsx", "xls"])
        if uploaded:
            try:
                df_upload = pd.read_excel(uploaded)
                df_upload = make_json_safe_df(df_upload)
                st.dataframe(df_upload.head(10), use_container_width=True)

                missing = [c for c in SALES_COLS if c not in df_upload.columns]
                if missing:
                    st.error(f"âŒ ì—…ë¡œë“œ íŒŒì¼ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
                else:
                    if st.button("âœ… íŒë§¤ ì—…ë¡œë“œ ì ìš©"):
                        if save_sales_data(df_upload):
                            st.session_state.sales_data = load_sales_data()
                            st.success(f"âœ… {len(df_upload)}ê°œ ì¶”ê°€!")
                            st.rerun()
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")

    with tab3:
        st.subheader("ì†Œì¬ ë§ˆìŠ¤í„° ê´€ë¦¬ (ì‹ ê·œ í…œí”Œë¦¿)")

        template_mat = pd.DataFrame(columns=MATERIAL_COLS)
        template_mat.loc[0] = ["BF-5933", "BF", "POLYESTER", 100, 30, "135X140", 275, 2, 1, 3]

        buffer2 = io.BytesIO()
        with pd.ExcelWriter(buffer2, engine="openpyxl") as writer:
            template_mat.to_excel(writer, index=False, sheet_name="ì†Œì¬ë°ì´í„°")

        st.download_button(
            "ğŸ“¥ ì†Œì¬ í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            buffer2.getvalue(),
            "ì†Œì¬í…œí”Œë¦¿_ì‹ ê·œ.xlsx",
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

        uploaded_mat = st.file_uploader("ì†Œì¬ Excel íŒŒì¼ ì„ íƒ", type=["xlsx", "xls"])
        if uploaded_mat:
            try:
                df_mat = pd.read_excel(uploaded_mat)
                st.dataframe(df_mat.head(20), use_container_width=True)

                missing = [c for c in MATERIAL_COLS if c not in df_mat.columns]
                if missing:
                    st.error(f"âŒ ì—…ë¡œë“œ íŒŒì¼ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
                else:
                    if st.button("âœ… ì†Œì¬ ì—…ë¡œë“œ ì ìš©"):
                        if save_material_data(df_mat):
                            st.session_state.material_data = load_material_data()
                            st.success("âœ… ì†Œì¬ ì¶”ê°€ ì™„ë£Œ!")
                            st.rerun()
            except Exception as e:
                st.error(f"âŒ ì˜¤ë¥˜: {e}")

# =========================
# 3) ëŒ€ì‹œë³´ë“œ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)
# =========================
elif menu == "ğŸ“Š ëŒ€ì‹œë³´ë“œ":
    st.title("ğŸ“Š íŒë§¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)")

    if st.session_state.sales_data.empty:
        st.warning("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df = enrich_sales_data(st.session_state.sales_data.copy())

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ì´ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", f"{df['ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰'].sum():,}ê°œ")
        c2.metric("ì´ ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", f"{df['ë‹¹ì‹œì¦ŒíŒë§¤ì•¡'].sum():,}ì›")

        total_qty = df["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum()
        total_amt = df["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"].sum()
        avg_price = (total_amt / total_qty) if total_qty > 0 else 0
        c3.metric("í‰ê·  íŒë§¤ë‹¨ê°€(íŒë§¤ì•¡/ìˆ˜ëŸ‰)", f"{avg_price:,.0f}ì›")
        c4.metric("ì´ SKU", f"{len(df):,}ê°œ")

        st.divider()

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ‘¥ ì„±ë³„ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰")
            gender_sales = df.groupby("ì„±ë³„")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum()
            fig1 = px.pie(values=gender_sales.values, names=gender_sales.index, hole=0.4)
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            st.subheader("ğŸ­ ì œì¡°ë°©ì‹ë³„ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰")
            manu_sales = df.groupby("ì œì¡°ë°©ì‹")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum().sort_values(ascending=False)
            fig2 = px.bar(x=manu_sales.values, y=manu_sales.index, orientation="h")
            fig2.update_layout(showlegend=False, xaxis_title="ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", yaxis_title="")
            st.plotly_chart(fig2, use_container_width=True)

        col3, col4 = st.columns(2)
        with col3:
            st.subheader("ğŸ“ ì¹´í…Œê³ ë¦¬ë³„ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰")
            category_sales = df.groupby("ì¹´í…Œê³ ë¦¬")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum().sort_values(ascending=False)
            fig3 = px.bar(x=category_sales.values, y=category_sales.index, orientation="h")
            fig3.update_layout(showlegend=False, xaxis_title="ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", yaxis_title="")
            st.plotly_chart(fig3, use_container_width=True)

        with col4:
            st.subheader("ğŸ‘• ì•„ì´í…œë³„ TOP 10 (ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰)")
            item_sales = df.groupby("ì•„ì´í…œëª…")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum().sort_values(ascending=False).head(10)
            fig4 = px.bar(x=item_sales.values, y=item_sales.index, orientation="h")
            fig4.update_layout(showlegend=False, xaxis_title="ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", yaxis_title="")
            st.plotly_chart(fig4, use_container_width=True)

        st.divider()
        col5, col6 = st.columns(2)
        with col5:
            st.subheader("ğŸŒˆ ì»¬ëŸ¬ë³„ TOP 10 (ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰)")
            color_sales = df.groupby("ì»¬ëŸ¬")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum().sort_values(ascending=False).head(10)
            fig5 = px.bar(x=color_sales.values, y=color_sales.index, orientation="h")
            fig5.update_layout(showlegend=False, xaxis_title="ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", yaxis_title="")
            st.plotly_chart(fig5, use_container_width=True)

        with col6:
            st.subheader("ğŸŒ¸ ì‹œì¦Œë³„ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰")
            season_sales = df.groupby("ì‹œì¦Œ")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum()
            fig6 = px.pie(values=season_sales.values, names=season_sales.index, hole=0.4)
            st.plotly_chart(fig6, use_container_width=True)

# =========================
# 4) ë­í‚¹ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)
# =========================
elif menu == "ğŸ† ë­í‚¹":
    st.title("ğŸ† ì¡°í•©ë³„ ì„±ê³¼ ë­í‚¹ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)")

    if st.session_state.sales_data.empty:
        st.warning("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df = enrich_sales_data(st.session_state.sales_data.copy())
        df["ì¡°í•©"] = df["ì„±ë³„"] + " / " + df["ì•„ì´í…œëª…"] + " / " + df["ì œì¡°ë°©ì‹"] + " / " + df["ì†Œì¬ëª…"] + " / " + df["í•"] + " / " + df["ê¸°ì¥"]

        combo_stats = df.groupby("ì¡°í•©").agg({
            "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰": ["sum", "mean", "count"],
            "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡": ["sum", "mean"],
        }).round(0)

        combo_stats.columns = ["ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë°ì´í„°ìˆ˜", "ì´ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"]
        combo_stats = combo_stats.reset_index()

        metric = st.radio("ë¶„ì„ ê¸°ì¤€", ["ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ì´ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"], horizontal=True)
        top_n = st.slider("í‘œì‹œí•  ì¡°í•© ìˆ˜", 5, 20, 10)

        col1, col2 = st.columns(2)
        with col1:
            st.subheader(f"ğŸ¥‡ Best {top_n}")
            top_combos = combo_stats.nlargest(top_n, metric)
            fig_top = px.bar(top_combos, x=metric, y="ì¡°í•©", orientation="h")
            fig_top.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig_top, use_container_width=True)
            st.dataframe(top_combos, use_container_width=True, hide_index=True)

        with col2:
            st.subheader(f"ğŸ¥‰ Worst {top_n}")
            bottom_combos = combo_stats.nsmallest(top_n, metric)
            fig_bottom = px.bar(bottom_combos, x=metric, y="ì¡°í•©", orientation="h")
            fig_bottom.update_layout(showlegend=False, yaxis={"categoryorder": "total descending"})
            st.plotly_chart(fig_bottom, use_container_width=True)
            st.dataframe(bottom_combos, use_container_width=True, hide_index=True)

        st.divider()
        st.subheader("ğŸ”¥ ì¡°í•© íˆíŠ¸ë§µ (ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰)")
        heatmap_x = st.selectbox("Xì¶•", ["ì•„ì´í…œëª…", "ì œì¡°ë°©ì‹", "ì†Œì¬ëª…", "í•", "ê¸°ì¥", "ì„±ë³„"])
        heatmap_y = st.selectbox("Yì¶•", ["ì œì¡°ë°©ì‹", "ì†Œì¬ëª…", "í•", "ê¸°ì¥", "ì•„ì´í…œëª…", "ì„±ë³„"],
                                 index=1 if heatmap_x == "ì•„ì´í…œëª…" else 0)
        if heatmap_x != heatmap_y:
            pivot = df.pivot_table(values="ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", index=heatmap_y, columns=heatmap_x, aggfunc="sum", fill_value=0)
            fig_heat = px.imshow(pivot, color_continuous_scale="RdYlGn", aspect="auto")
            fig_heat.update_layout(xaxis_title=heatmap_x, yaxis_title=heatmap_y)
            st.plotly_chart(fig_heat, use_container_width=True)

# =========================
# 5) ì†Œì¬ ë¶„ì„ (ë‹¹ì‹œì¦Œ ê¸°ì¤€ + GU/RA/SA ìƒê´€/êµ¬ê°„)
# =========================
elif menu == "ğŸ§µ ì†Œì¬ ë¶„ì„":
    st.title("ğŸ§µ ì†Œì¬ë³„ ì„±ê³¼ ë¶„ì„ (ë‹¹ì‹œì¦Œ ê¸°ì¤€)")

    if st.session_state.sales_data.empty:
        st.warning("âš ï¸ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        df = enrich_sales_data(st.session_state.sales_data.copy())

        material_stats = df.groupby("ì†Œì¬ëª…").agg({
            "ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰": ["sum", "mean", "count"],
            "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡": ["sum", "mean"],
            "í’ˆë²ˆ": "nunique",
        }).round(0)

        material_stats.columns = ["ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë°ì´í„°ìˆ˜", "ì´ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "í‰ê· ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "SKUìˆ˜"]
        material_stats = material_stats.reset_index().sort_values("ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", ascending=False)

        st.subheader("ğŸ“Š ì†Œì¬ë³„ ì„±ê³¼ ìš”ì•½")
        st.dataframe(material_stats, use_container_width=True, hide_index=True)

        st.divider()
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("ğŸ§µ ì†Œì¬ë³„ ì´ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰ TOP 10")
            fig1 = px.bar(material_stats.head(10), x="ì´ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", y="ì†Œì¬ëª…", orientation="h")
            fig1.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig1, use_container_width=True)

        with col2:
            st.subheader("ğŸ’° ì†Œì¬ë³„ ì´ ë‹¹ì‹œì¦ŒíŒë§¤ì•¡ TOP 10")
            fig2 = px.bar(material_stats.head(10), x="ì´ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", y="ì†Œì¬ëª…", orientation="h")
            fig2.update_layout(showlegend=False, yaxis={"categoryorder": "total ascending"})
            st.plotly_chart(fig2, use_container_width=True)

        st.divider()
        st.subheader("ğŸ” ì†Œì¬ë³„ ìƒì„¸ ë¶„ì„")
        selected_material = st.selectbox("ì†Œì¬ ì„ íƒ", material_stats["ì†Œì¬ëª…"].tolist())

        if selected_material:
            mdf = df[df["ì†Œì¬ëª…"] == selected_material]

            c1, c2, c3 = st.columns(3)
            c1.metric("ì´ ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", f"{mdf['ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰'].sum():,}ê°œ")
            c2.metric("í‰ê·  ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", f"{mdf['ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰'].mean():.0f}ê°œ")
            c3.metric("ì‚¬ìš© SKU", f"{mdf['í’ˆë²ˆ'].nunique():,}ê°œ")

            st.markdown(f"#### {selected_material} ì•„ì´í…œë³„ ì„±ê³¼(ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰)")
            item_perf = mdf.groupby("ì•„ì´í…œëª…")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum().sort_values(ascending=False)
            fig3 = px.bar(x=item_perf.values, y=item_perf.index, orientation="h")
            fig3.update_layout(showlegend=False, xaxis_title="ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", yaxis_title="")
            st.plotly_chart(fig3, use_container_width=True)

            st.markdown(f"#### {selected_material} ì œì¡°ë°©ì‹ë³„ ì„±ê³¼(ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰)")
            manu_perf = mdf.groupby("ì œì¡°ë°©ì‹")["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"].sum().sort_values(ascending=False)
            fig4 = px.pie(values=manu_perf.values, names=manu_perf.index, hole=0.4)
            st.plotly_chart(fig4, use_container_width=True)

            if not st.session_state.material_data.empty:
                info = st.session_state.material_data[st.session_state.material_data["ì†Œì¬ëª…"] == selected_material]
                if not info.empty:
                    st.markdown("#### ğŸ“‹ ì†Œì¬ ë§ˆìŠ¤í„°(ë¬¼ì„±/ê´‘íƒ/ê±°ì¹ ê¸°)")
                    st.dataframe(info[MATERIAL_COLS], use_container_width=True, hide_index=True)
                else:
                    st.info("ì†Œì¬ ë§ˆìŠ¤í„°ì— í•´ë‹¹ ì†Œì¬ëª…ì´ ì—†ìŠµë‹ˆë‹¤(ì†Œì¬ëª… ë¶ˆì¼ì¹˜/ë¯¸ë“±ë¡).")

        st.divider()
        st.subheader("ğŸ“ˆ GU/RA/SA â†” íŒë§¤ ìƒê´€/êµ¬ê°„ ë¶„ì„ (ì†Œì¬ ë§ˆìŠ¤í„° ì¡°ì¸)")

        if st.session_state.material_data.empty:
            st.warning("ì†Œì¬ ë§ˆìŠ¤í„°(material_data)ê°€ ë¹„ì–´ ìˆì–´ GU/RA/SA ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sales_df = st.session_state.sales_data.copy()
            mat_df = st.session_state.material_data.copy()

            sales_df["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"] = pd.to_numeric(sales_df["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰"], errors="coerce").fillna(0)
            sales_df["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"] = pd.to_numeric(sales_df["ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"], errors="coerce").fillna(0)

            for c in ["GU", "RA", "SA"]:
                mat_df[c] = pd.to_numeric(mat_df[c], errors="coerce")

            mat_small = mat_df[["ì†Œì¬ëª…", "GU", "RA", "SA"]].drop_duplicates(subset=["ì†Œì¬ëª…"])
            merged = sales_df.merge(mat_small, on="ì†Œì¬ëª…", how="left")

            missing_prop = merged["GU"].isna().mean() if len(merged) else 1.0
            st.caption(f"ì†Œì¬ ë§ˆìŠ¤í„°(GU/RA/SA) ë¯¸ë§¤ì¹­ ë¹„ìœ¨: **{missing_prop*100:.1f}%** (ì†Œì¬ëª… ë¶ˆì¼ì¹˜/ë¯¸ë“±ë¡ ê°€ëŠ¥)")

            scope = st.radio("ë¶„ì„ ë²”ìœ„", ["ì „ì²´ ì†Œì¬", "ì„ íƒí•œ ì†Œì¬ë§Œ"], horizontal=True)
            if scope == "ì„ íƒí•œ ì†Œì¬ë§Œ":
                if "selected_material" in locals() and selected_material:
                    merged_scope = merged[merged["ì†Œì¬ëª…"] == selected_material].copy()
                else:
                    merged_scope = merged.iloc[0:0].copy()
            else:
                merged_scope = merged.copy()

            if merged_scope.empty:
                st.warning("ì„ íƒ ë²”ìœ„ì— ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.markdown("### 1) ìƒê´€ë¶„ì„ (Pearson)")
                target_metric = st.selectbox("íŒë§¤ ì§€í‘œ", ["ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "ë‹¹ì‹œì¦ŒíŒë§¤ì•¡"], index=0)

                corr_rows = []
                for c in ["GU", "RA", "SA"]:
                    corr = _safe_corr(merged_scope[c], merged_scope[target_metric])
                    n = int(pd.concat([merged_scope[c], merged_scope[target_metric]], axis=1).dropna().shape[0])
                    corr_rows.append({"ì§€í‘œ": c, "corr": corr, "ìƒ˜í”Œìˆ˜": n})

                st.dataframe(pd.DataFrame(corr_rows), use_container_width=True, hide_index=True)

                st.markdown("### 2) êµ¬ê°„(ë¹ˆ) ë¹„êµ ë¶„ì„")
                bin_metric = st.selectbox("êµ¬ê°„í™”í•  ë¬¼ì„± ì§€í‘œ", ["GU", "RA", "SA"], index=0)
                bin_method = st.radio("êµ¬ê°„í™” ë°©ì‹", ["equal_width", "quantile"], horizontal=True)
                bin_count = st.slider("êµ¬ê°„ ìˆ˜", 2, 6, 4)

                tmp = merged_scope.dropna(subset=[bin_metric]).copy()
                if tmp.empty:
                    st.warning("êµ¬ê°„ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í•´ë‹¹ ì§€í‘œê°€ ë¹„ì–´ìˆìŒ)")
                else:
                    bins = _bin_series(tmp[bin_metric], method=bin_method, bins=bin_count)
                    if bins is None:
                        st.warning("êµ¬ê°„ ìƒì„± ì‹¤íŒ¨ (ë°ì´í„° ë¶€ì¡±)")
                    else:
                        tmp["êµ¬ê°„"] = bins.astype(str)
                        agg = tmp.groupby("êµ¬ê°„").agg(
                            í‘œë³¸ìˆ˜=("í’ˆë²ˆ", "count"),
                            íŒë§¤ìˆ˜ëŸ‰_í•©=("ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "sum"),
                            íŒë§¤ìˆ˜ëŸ‰_í‰ê· =("ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "mean"),
                            íŒë§¤ì•¡_í•©=("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "sum"),
                            íŒë§¤ì•¡_í‰ê· =("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "mean"),
                        ).reset_index()

                        for c in ["íŒë§¤ìˆ˜ëŸ‰_í‰ê· ", "íŒë§¤ì•¡_í‰ê· "]:
                            agg[c] = agg[c].round(2)

                        st.dataframe(agg, use_container_width=True, hide_index=True)

                        colA, colB = st.columns(2)
                        with colA:
                            fig_q = px.bar(agg, x="êµ¬ê°„", y="íŒë§¤ìˆ˜ëŸ‰_í‰ê· ",
                                           title=f"{bin_metric} êµ¬ê°„ë³„ í‰ê·  ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰")
                            st.plotly_chart(fig_q, use_container_width=True)
                        with colB:
                            fig_a = px.bar(agg, x="êµ¬ê°„", y="íŒë§¤ì•¡_í‰ê· ",
                                           title=f"{bin_metric} êµ¬ê°„ë³„ í‰ê·  ë‹¹ì‹œì¦ŒíŒë§¤ì•¡")
                            st.plotly_chart(fig_a, use_container_width=True)

                st.markdown("### 3) (ì˜µì…˜) ì†Œì¬ ë‹¨ìœ„ ìš”ì•½")
                if st.checkbox("ì†Œì¬ëª… ë‹¨ìœ„ë¡œ ìš”ì•½ ë³´ê¸°", value=False):
                    mat_level = merged_scope.groupby("ì†Œì¬ëª…").agg(
                        GU=("GU", "mean"),
                        RA=("RA", "mean"),
                        SA=("SA", "mean"),
                        íŒë§¤ìˆ˜ëŸ‰=("ë‹¹ì‹œì¦ŒíŒë§¤ìˆ˜ëŸ‰", "sum"),
                        íŒë§¤ì•¡=("ë‹¹ì‹œì¦ŒíŒë§¤ì•¡", "sum"),
                        SKUìˆ˜=("í’ˆë²ˆ", "nunique"),
                    ).reset_index()
                    mat_level = mat_level.dropna(subset=["GU", "RA", "SA"], how="all")
                    st.dataframe(mat_level.sort_values("íŒë§¤ìˆ˜ëŸ‰", ascending=False).head(30),
                                 use_container_width=True, hide_index=True)

# =========================
# 6) ë°ì´í„° ê´€ë¦¬
# =========================
elif menu == "ğŸ’¾ ë°ì´í„° ê´€ë¦¬":
    st.title("ğŸ’¾ ë°ì´í„° ê´€ë¦¬")

    tab1, tab2, tab3 = st.tabs(["ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", "ğŸ“Š ë°ì´í„° í™•ì¸/í¸ì§‘", "ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ"])

    with tab1:
        st.subheader("ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("#### íŒë§¤ ë°ì´í„°")
            if not st.session_state.sales_data.empty:
                buffer1 = io.BytesIO()
                with pd.ExcelWriter(buffer1, engine="openpyxl") as writer:
                    st.session_state.sales_data[SALES_COLS].to_excel(writer, index=False, sheet_name="íŒë§¤ë°ì´í„°")
                st.download_button(
                    "ğŸ“¥ íŒë§¤ ë°ì´í„° Excel ë‹¤ìš´ë¡œë“œ",
                    buffer1.getvalue(),
                    f"íŒë§¤ë°ì´í„°_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                csv1 = st.session_state.sales_data[SALES_COLS].to_csv(index=False, encoding="utf-8-sig")
                st.download_button(
                    "ğŸ“¥ íŒë§¤ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
                    csv1,
                    f"íŒë§¤ë°ì´í„°_{datetime.now().strftime('%Y%m%d')}.csv",
                    "text/csv"
                )
            else:
                st.info("ë‹¤ìš´ë¡œë“œí•  íŒë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with col2:
            st.markdown("#### ì†Œì¬ ë°ì´í„°")
            if not st.session_state.material_data.empty:
                buffer2 = io.BytesIO()
                with pd.ExcelWriter(buffer2, engine="openpyxl") as writer:
                    st.session_state.material_data[MATERIAL_COLS].to_excel(writer, index=False, sheet_name="ì†Œì¬ë°ì´í„°")
                st.download_button(
                    "ğŸ“¥ ì†Œì¬ ë°ì´í„° Excel ë‹¤ìš´ë¡œë“œ",
                    buffer2.getvalue(),
                    f"ì†Œì¬ë°ì´í„°_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.info("ë‹¤ìš´ë¡œë“œí•  ì†Œì¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab2:
        st.subheader("ğŸ“Š ë°ì´í„° í™•ì¸ ë° í¸ì§‘ (ë¡œì»¬)")
        st.caption("âš ï¸ data_editorì—ì„œ ìˆ˜ì •í•œ ê°’ì€ DB ì—…ë°ì´íŠ¸ë¡œ ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤(í˜„ì¬ ë²„ì „ì€ insert/delete ì¤‘ì‹¬).")
        data_type = st.radio("ë°ì´í„° ìœ í˜•", ["íŒë§¤ ë°ì´í„°", "ì†Œì¬ ë°ì´í„°"], horizontal=True)

        if data_type == "íŒë§¤ ë°ì´í„°":
            if not st.session_state.sales_data.empty:
                edited_sales = st.data_editor(
                    st.session_state.sales_data[SALES_COLS],
                    use_container_width=True,
                    num_rows="dynamic"
                )
                if st.button("ğŸ’¾ (ë¡œì»¬) íŒë§¤ ë³€ê²½ì‚¬í•­ ë°˜ì˜"):
                    st.session_state.sales_data = edited_sales
                    st.success("âœ… ë¡œì»¬ ë³€ê²½ì‚¬í•­ ë°˜ì˜ ì™„ë£Œ (DB ì—…ë°ì´íŠ¸ëŠ” ì•„ë‹˜)")
                    st.rerun()
            else:
                st.warning("í¸ì§‘í•  íŒë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if not st.session_state.material_data.empty:
                edited_mat = st.data_editor(
                    st.session_state.material_data[MATERIAL_COLS],
                    use_container_width=True,
                    num_rows="dynamic"
                )
                if st.button("ğŸ’¾ (ë¡œì»¬) ì†Œì¬ ë³€ê²½ì‚¬í•­ ë°˜ì˜"):
                    st.session_state.material_data = edited_mat
                    st.success("âœ… ë¡œì»¬ ë³€ê²½ì‚¬í•­ ë°˜ì˜ ì™„ë£Œ (DB ì—…ë°ì´íŠ¸ëŠ” ì•„ë‹˜)")
                    st.rerun()
            else:
                st.warning("í¸ì§‘í•  ì†Œì¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with tab3:
        st.subheader("ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ")
        st.warning("âš ï¸ **ì£¼ì˜**: ì‚­ì œëœ ë°ì´í„°ëŠ” ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤! ë¨¼ì € ë°±ì—…ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
        c1, c2 = st.columns(2)
        with c1:
            if st.button("ğŸ—‘ï¸ íŒë§¤ ë°ì´í„° ì „ì²´ ì‚­ì œ", type="secondary"):
                if delete_all_sales_data():
                    st.session_state.sales_data = load_sales_data()
                    st.success("âœ… íŒë§¤ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
        with c2:
            if st.button("ğŸ—‘ï¸ ì†Œì¬ ë°ì´í„° ì „ì²´ ì‚­ì œ", type="secondary"):
                if delete_all_material_data():
                    st.session_state.material_data = load_material_data()
                    st.success("âœ… ì†Œì¬ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()

# =========================
# Footer
# =========================
st.sidebar.divider()
st.sidebar.info(f"""
ğŸ“Š **í˜„ì¬ ë°ì´í„° í˜„í™©**
- íŒë§¤ ë°ì´í„°: {len(st.session_state.sales_data)}ê±´
- ì†Œì¬ ë°ì´í„°: {len(st.session_state.material_data)}ê±´

ğŸ’¡ **ë°ì´í„° ì €ì¥**
- Supabase í´ë¼ìš°ë“œì— ì˜êµ¬ ì €ì¥
- ë¸Œë¼ìš°ì € ì¢…ë£Œí•´ë„ ë°ì´í„° ìœ ì§€

ğŸ”„ **ìƒˆë¡œê³ ì¹¨**
- ìºì‹œ ì‹œê°„: 10ë¶„
""")
st.sidebar.markdown("---")
st.sidebar.caption("Â© 2025 ì„¸ë¥´ì§€ì˜¤íƒ€í‚¤ë‹ˆ íŒë§¤ë¶„ì„ì‹œìŠ¤í…œ (Streamlit+Supabase)")
